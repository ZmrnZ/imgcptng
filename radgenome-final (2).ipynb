{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6322179,"sourceType":"datasetVersion","datasetId":3638326},{"sourceId":6322203,"sourceType":"datasetVersion","datasetId":3638341},{"sourceId":7235830,"sourceType":"datasetVersion","datasetId":4174104},{"sourceId":8490198,"sourceType":"datasetVersion","datasetId":5065249},{"sourceId":11897419,"sourceType":"datasetVersion","datasetId":7478701},{"sourceId":12312113,"sourceType":"datasetVersion","datasetId":7760475},{"sourceId":12457774,"sourceType":"datasetVersion","datasetId":7735340},{"sourceId":12466730,"sourceType":"datasetVersion","datasetId":7864823},{"sourceId":12995325,"sourceType":"datasetVersion","datasetId":8133656},{"sourceId":13519808,"sourceType":"datasetVersion","datasetId":8367456},{"sourceId":451942,"sourceType":"modelInstanceVersion","modelInstanceId":366596,"modelId":387499},{"sourceId":505407,"sourceType":"modelInstanceVersion","modelInstanceId":401363,"modelId":419455},{"sourceId":647127,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":488039,"modelId":503462}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install and Import Libraries","metadata":{}},{"cell_type":"code","source":"! pip install sentencepiece\n! pip install transformers\n! pip install datasets\n! pip install sacremoses\n! pip install accelerate\n! pip install sacrebleu\n! pip install bert_score\n! pip install sentence_transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T05:01:46.382611Z","iopub.execute_input":"2025-12-08T05:01:46.382857Z","iopub.status.idle":"2025-12-08T05:03:00.414290Z","shell.execute_reply.started":"2025-12-08T05:01:46.382831Z","shell.execute_reply":"2025-12-08T05:03:00.413453Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses) (2024.5.15)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses) (1.4.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses) (4.66.4)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.33.0)\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.24.6)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.2.0 sacrebleu-2.5.1\nCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.4.0)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.2.2)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.44.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.24.6)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.19.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.7.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\nCollecting sentence_transformers\n  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.0)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.24.6)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-5.1.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport glob\nimport json\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport nibabel as nib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport torch\nimport sacrebleu\n\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom skimage.measure import label, regionprops\nfrom transformers import (\n    VisionEncoderDecoderModel, AutoTokenizer, ViTFeatureExtractor,\n    AutoModelForSeq2SeqLM, AutoTokenizer as AutoTokenizerLM,\n    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n)\nfrom datasets import Dataset\nfrom sentence_transformers import SentenceTransformer, util\nfrom bert_score import score as bert_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T05:03:00.416125Z","iopub.execute_input":"2025-12-08T05:03:00.416415Z","iopub.status.idle":"2025-12-08T05:03:20.744928Z","shell.execute_reply.started":"2025-12-08T05:03:00.416386Z","shell.execute_reply":"2025-12-08T05:03:20.744024Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"markdown","source":"Sementara hanya menggunakan dataset GLI ","metadata":{}},{"cell_type":"code","source":"# Load data split radgenome\ndef load_json_files():\n    with open('/kaggle/input/radgenome-caption/train.json', 'r') as f:\n        train_data = json.load(f)\n    with open('/kaggle/input/radgenome-caption/val.json', 'r') as f:\n        val_data = json.load(f)\n    with open('/kaggle/input/radgenome-caption/test.json', 'r') as f:\n        test_data = json.load(f)\n    return train_data, val_data, test_data\n\n# Load caption dari dataset radgenome\ndef load_captions():\n    caption_files = {\n        # 'BraTS_MET': '/kaggle/input/radgenome-caption/BraTS_MET/modal_wise_finding.json',\n        # 'BraTS_MEN': '/kaggle/input/radgenome-caption/BraTS_MEN/modal_wise_finding.json',\n        'BraTS_GLI': '/kaggle/input/radgenome-caption/BraTS_GLI/modal_wise_finding.json'\n    }\n    captions = {}\n    for dataset, file_path in caption_files.items():\n        with open(file_path, 'r') as f:\n            captions[dataset] = json.load(f)\n    return captions\n\n# Fungsi untuk dapatkan path image\ndef get_image_path(filename):\n    if filename.startswith('BraTS-GLI'):\n        prefix = filename.rsplit('-', 1)[0]\n        return f\"/kaggle/input/brats2023-part-1/{prefix}/{filename}.nii\"\n    elif filename.startswith('BraTS-MEN'):\n        prefix = filename.rsplit('-', 1)[0]\n        path1 = f\"/kaggle/input/brats-men/BraTS-MEN-Train/{prefix}/{filename}.nii\"\n        path2 = f\"/kaggle/input/meningits-part2/BraTS-MEN-Train2/{prefix}/{filename}.nii\"\n        return path1 if os.path.exists(path1) else path2\n    elif filename.startswith('BraTS-MET'):\n        prefix = filename.rsplit('-', 1)[0]\n        train_path = f\"/kaggle/input/brats2023/brats2023/brats2023-training/{prefix}/{filename}.nii\"\n        val_path = f\"/kaggle/input/brats2023/brats2023/brats2023-validation/{prefix}/{filename}.nii\"\n        return train_path if os.path.exists(train_path) else val_path\n    return None\n\n# Ambil caption dan kategori (ini buat captioning nanti, segmentasi blm perlu)\ndef get_caption(filename, captions):\n    if filename.startswith('BraTS-GLI'):\n        return captions['BraTS_GLI'].get(filename, '')\n    elif filename.startswith('BraTS-MEN'):\n        return captions['BraTS_MEN'].get(filename, '')\n    elif filename.startswith('BraTS-MET'):\n        return captions['BraTS_MET'].get(filename, '')\n    return ''\n\ndef get_category(filename):\n    if filename.startswith('BraTS-GLI'):\n        return 'GLI'\n    elif filename.startswith('BraTS-MEN'):\n        return 'MEN'\n    elif filename.startswith('BraTS-MET'):\n        return 'MET'\n    return 'Unknown'\n\n# Dapatkan path segmentasi dari image path\ndef get_segmentation_path(row):\n    image_path = row['image_path']\n    category = row['category']\n    if image_path is None:\n        return None\n    if category in ['GLI', 'MEN', 'MET']:\n        seg_filename = row['filename'].rsplit('-', 1)[0] + '-seg.nii'\n        return os.path.join(os.path.dirname(image_path), seg_filename)\n    return None\n\ndef process_dataset(filenames, captions):\n    data = []\n    for filename in filenames:\n        # sementara hanya proses GLI\n        if not filename.startswith('BraTS-GLI'):\n            continue\n            \n        if filename.startswith('sub-strokecase'):\n            continue\n            \n        if filename.startswith(('GE3T', 'Singapore', 'Utrecht')):\n            continue  # skip WMH\n            \n        image_path = get_image_path(filename)\n        if image_path is None or not os.path.exists(image_path):\n            continue\n        caption = get_caption(filename, captions)\n        category = get_category(filename)\n        data.append({\n            'filename': filename,\n            'image_path': image_path,\n            'caption': caption,\n            'category': category\n        })\n    df = pd.DataFrame(data)\n    df['segmentation_path'] = df.apply(get_segmentation_path, axis=1)\n    df = df[df['segmentation_path'].notna()]\n    df = df[df['segmentation_path'].apply(lambda x: isinstance(x, str) and os.path.exists(x))].reset_index(drop=True)\n    return df\n\n# # Eksekusi all pipeline\n# train_data, val_data, test_data = load_json_files()\n# captions = load_captions()\n\n# # Jika ingin menggunakan semua dataset (MEN dan MET)\n# # all_filenames = train_data + val_data + test_data\n\n# # Sementara gunakan dataset GLI terlebih dahulu\n# all_filenames = [fn for fn in (train_data + val_data + test_data) if fn.startswith('BraTS-GLI')]\n# df = process_dataset(all_filenames, captions)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split train val test sesuai split dari radgenome di awal tadi\ntrain_data, val_data, test_data = load_json_files()\ncaptions = load_captions()\n\n# process_dataset dipanggil untuk tiap split & gabungkan\ntrain_df_src = process_dataset(train_data, captions)\nval_df_src   = process_dataset(val_data, captions)\ntest_df_src  = process_dataset(test_data, captions)\ncombined = pd.concat([train_df_src, val_df_src, test_df_src], ignore_index=True)\n\n# Base Extraction\ncombined['base'] = combined['filename'].apply(lambda x: str(x).rsplit(\"-\",1)[0])\nbases = combined.groupby('base').first().reset_index()\n\n# stratified split di level base\ntrain_frac = 0.60\ntemp_frac = 1.0 - train_frac\nval_frac_of_temp = 0.5\nRANDOM_STATE = 42\n\ntrain_bases, temp_bases = train_test_split(\n    bases,\n    stratify=bases['category'],\n    test_size=(1.0 - train_frac),\n    random_state=RANDOM_STATE\n)\n\nval_bases, test_bases = train_test_split(\n    temp_bases,\n    stratify=temp_bases['category'],\n    test_size=val_frac_of_temp,\n    random_state=RANDOM_STATE\n)\n\ntrain_df = combined[combined['base'].isin(train_bases['base'])].drop(columns=['base']).reset_index(drop=True)\nvalidation_df = combined[combined['base'].isin(val_bases['base'])].drop(columns=['base']).reset_index(drop=True)\ntest_df = combined[combined['base'].isin(test_bases['base'])].drop(columns=['base']).reset_index(drop=True)\n\n# simpan hasil rebalanced\ntrain_df.to_csv(\"train_dataset_rebalanced.csv\", index=False)\nvalidation_df.to_csv(\"val_dataset_rebalanced.csv\", index=False)\ntest_df.to_csv(\"test_dataset_rebalanced.csv\", index=False)\n\nprint(\"Train dataset:\")\ntrain_counts = train_df['category'].value_counts()\nfor category, count in train_counts.items():\n    print(f\"{category}: {count}\")\nprint(f\"Total: {len(train_df)}\")\n\nprint(\"\\nValidation dataset:\")\nval_counts = validation_df['category'].value_counts()\nfor category, count in val_counts.items():\n    print(f\"{category}: {count}\")\nprint(f\"Total: {len(validation_df)}\")\n\nprint(\"\\nTest dataset:\")\ntest_counts = test_df['category'].value_counts()\nfor category, count in test_counts.items():\n    print(f\"{category}: {count}\")\nprint(f\"Total: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # perlu rebalance split data (karena split yang dibikin dari si radgenome ga fair, ada kategori yang samplenya kurang di bbrp split)\n\n# np.random.seed(42)\n\n# train_indices = train_df.index.tolist()\n# sample_size = min(400, len(train_indices))\n# random_indices = np.random.choice(train_indices, size=sample_size, replace=False)\n\n# train_to_val = train_df.loc[random_indices]\n# validation_df = pd.concat([validation_df, train_to_val], ignore_index=True)\n\n# train_df = train_df.drop(random_indices)\n\n# met_train_data = train_df[train_df['category'] == 'MET']\n# met_sample_size = min(90, len(met_train_data))\n# met_to_test_indices = np.random.choice(met_train_data.index, size=met_sample_size, replace=False)\n# met_to_test = train_df.loc[met_to_test_indices]\n\n# test_df = pd.concat([test_df, met_to_test], ignore_index=True)\n# train_df = train_df.drop(met_to_test_indices)\n\n# train_df = train_df.reset_index(drop=True)\n# validation_df = validation_df.reset_index(drop=True)\n# test_df = test_df.reset_index(drop=True)\n\n# train_df.to_csv('train_dataset_rebalanced.csv', index=False)\n# validation_df.to_csv('val_dataset_rebalanced.csv', index=False)\n# test_df.to_csv('test_dataset_rebalanced.csv', index=False)\n\n# print(\"Rebalanced Train dataset:\")\n# train_counts = train_df['category'].value_counts()\n# for category, count in train_counts.items():\n#     print(f\"{category}: {count}\")\n# print(f\"Total: {len(train_df)}\")\n\n# print(\"\\nRebalanced Validation dataset:\")\n# val_counts = validation_df['category'].value_counts()\n# for category, count in val_counts.items():\n#     print(f\"{category}: {count}\")\n# print(f\"Total: {len(validation_df)}\")\n\n# print(\"\\nRebalanced Test dataset:\")\n# test_counts = test_df['category'].value_counts()\n# for category, count in test_counts.items():\n#     print(f\"{category}: {count}\")\n# print(f\"Total: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.head())","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load Model Segmentasi & Generate Predicted Segmentation","metadata":{}},{"cell_type":"code","source":"# Load model segmentasi\nSEG_MODEL_PATH = \"/kaggle/input/3d-mri-brain-segmentation/keras/default/1/3D_MRI_Brain_tumor_segmentation.h5\"\nPRED_OUT_DIR = Path(\"/kaggle/working/predicted_masks\")\nPRED_OUT_DIR.mkdir(parents=True, exist_ok=True)\nIMG_SIZE = 128  \nTEST_RUN = False  # set False to run full dataset (but test True first)\nTEST_N = 12","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dice loss\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n        \n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss / class_num\n\n    return total_loss\n\n# define per class evaluation of dice coef\n# inspired by https://github.com/keras-team/keras/issues/9395\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n# Computing Precision \ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    \n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seg_model = tf.keras.models.load_model(\n    SEG_MODEL_PATH,\n    custom_objects={\n        'dice_coef': dice_coef,\n        'precision': precision,\n        'sensitivity': sensitivity,\n        'specificity': specificity,\n        'dice_coef_necrotic': dice_coef_necrotic,\n        'dice_coef_edema': dice_coef_edema,\n        'dice_coef_enhancing': dice_coef_enhancing\n    },\n    compile=False\n)\nprint(\"Loaded segmentation model. GPU available:\", bool(tf.config.list_physical_devices(\"GPU\")))\nprint(\"Model input shape:\", getattr(seg_model, \"input_shape\", None))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_slice_from_vol(vol, idx, img_size=IMG_SIZE):\n    sl = vol[:, :, idx].astype(np.float32)\n    slr = cv2.resize(sl, (img_size, img_size), interpolation=cv2.INTER_LINEAR)\n    maxv = slr.max()\n    if maxv > 0:\n        slr = slr / maxv\n    return slr\n\ndef predict_full_volume_singlefile(image_path, seg_out_path, mode='duplicate'):\n    vol_obj = nib.load(image_path)\n    vol = vol_obj.get_fdata()\n    affine = vol_obj.affine\n    H, W, Z = vol.shape\n    seg_resized = np.zeros((IMG_SIZE, IMG_SIZE, Z), dtype=np.uint8)\n\n    for k in range(Z):\n        s1 = preprocess_slice_from_vol(vol, k)\n        if mode == 'duplicate':\n            s2 = s1\n        elif mode == 'zeros':\n            s2 = np.zeros_like(s1)\n        else:\n            s2 = s1\n\n        X = np.zeros((1, IMG_SIZE, IMG_SIZE, 2), dtype=np.float32)\n        X[0, :, :, 0] = s1\n        X[0, :, :, 1] = s2\n\n        pred = seg_model.predict(X, verbose=0)\n        lbl = np.argmax(pred[0], axis=-1).astype(np.uint8)\n        seg_resized[:, :, k] = lbl\n\n    # resize back to original H,W using nearest neighbor (labels)\n    seg_out = np.zeros((H, W, Z), dtype=np.uint8)\n    for k in range(Z):\n        seg_out[:, :, k] = cv2.resize(seg_resized[:, :, k], (W, H), interpolation=cv2.INTER_NEAREST)\n\n    nib.save(nib.Nifti1Image(seg_out, affine=affine), str(seg_out_path))\n    return True\n\ndef predict_full_volume_pair(image_path_A, image_path_B, seg_out_path):\n    \"\"\"\n    image_path_A: FLAIR-like (t2f) path\n    image_path_B: T1-CE path (must exist)\n    Produces seg_out_path (canonical per-base).\n    \"\"\"\n    # load volumes\n    objA = nib.load(image_path_A); volA = objA.get_fdata()\n    objB = nib.load(image_path_B); volB = objB.get_fdata()\n    # ensure shapes match (they should in BraTS)\n    if volA.shape != volB.shape:\n        raise ValueError(f\"Shape mismatch: {image_path_A} {volA.shape} vs {image_path_B} {volB.shape}\")\n\n    affine = objA.affine\n    H, W, Z = volA.shape\n    seg_resized = np.zeros((IMG_SIZE, IMG_SIZE, Z), dtype=np.uint8)\n\n    for k in range(Z):\n        a = preprocess_slice_from_vol(volA, k)\n        b = preprocess_slice_from_vol(volB, k)\n        X = np.zeros((1, IMG_SIZE, IMG_SIZE, 2), dtype=np.float32)\n        X[0, :, :, 0] = a\n        X[0, :, :, 1] = b\n\n        pred = seg_model.predict(X, verbose=0)\n        lbl = np.argmax(pred[0], axis=-1).astype(np.uint8)\n        seg_resized[:, :, k] = lbl\n\n    seg_out = np.zeros((H, W, Z), dtype=np.uint8)\n    for k in range(Z):\n        seg_out[:, :, k] = cv2.resize(seg_resized[:, :, k], (W, H), interpolation=cv2.INTER_NEAREST)\n\n    nib.save(nib.Nifti1Image(seg_out, affine=affine), str(seg_out_path))\n    return True\n\ndef generate_predseg_per_row_and_update_df(df, out_dir=PRED_OUT_DIR):\n    \"\"\"\n    For each base in df: if BOTH t2f (FLAIR-like) and t1c (T1-CE) exist,\n    generate one canonical <base>-predseg.nii using predict_full_volume_pair(),\n    then propagate that path to all rows (all modalities) of that base.\n\n    If t1c missing for a base -> leave pred_seg_path empty for that base.\n    \"\"\"\n    out_dir.mkdir(parents=True, exist_ok=True)\n    pred_map = {}  # base -> pred_path (only for bases where pair exists)\n\n    # choose iteration set for pass1: debug small set if TEST_RUN True\n    rows_for_pass1 = list(df.head(TEST_N).itertuples(index=False)) if TEST_RUN else list(df.itertuples(index=False))\n\n    # PASS 1: generate pair preds for bases that have both t2f and t1c\n    for r in tqdm(rows_for_pass1, desc=\"Pass1: generate pair preds\"):\n        fname = str(getattr(r, 'filename'))\n        base = fname.rsplit('-', 1)[0]\n        if base in pred_map:\n            continue\n\n        # gather rows for this base from full df\n        rows_base = df[df['filename'].str.startswith(base)]\n        p_t2 = None\n        p_t1c = None\n        for _, rr in rows_base.iterrows():\n            fn = str(rr['filename']).lower()\n            p = rr['image_path']\n            if 't2f' in fn or 'flair' in fn:\n                p_t2 = p\n            if 't1c' in fn or 't1ce' in fn:\n                p_t1c = p\n\n        # require both paths to exist on disk\n        if not p_t2 or not p_t1c:\n            # either no t2f or no t1c → skip this base\n            continue\n        if not Path(p_t2).exists() or not Path(p_t1c).exists():\n            # missing file on disk → skip\n            continue\n\n        # canonical output name per base (no modality suffix)\n        out_name = f\"{base}-predseg.nii\"\n        out_path = out_dir / out_name\n\n        if not out_path.exists():\n            try:\n                predict_full_volume_pair(p_t2, p_t1c, out_path)\n            except Exception as e:\n                print(\"pair predict failed for\", base, p_t2, p_t1c, \"error:\", e)\n                continue\n\n        pred_map[base] = str(out_path)\n\n    # PASS 2: propagate pred_map to all rows of df\n    pred_paths = []\n    for _, row in df.iterrows():\n        base = str(row['filename']).rsplit('-', 1)[0]\n        pred_paths.append(pred_map.get(base, \"\"))\n\n    df['pred_seg_path'] = pred_paths\n    return df","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = generate_predseg_per_row_and_update_df(train_df)\ntrain_df.to_csv('train_dataset_rebalanced_with_predseg.csv', index=False)\n\nval_df = generate_predseg_per_row_and_update_df(validation_df)\nval_df.to_csv('val_dataset_rebalanced_with_predseg.csv', index=False)\n\ntest_df = generate_predseg_per_row_and_update_df(test_df)\ntest_df.to_csv('test_dataset_rebalanced_with_predseg.csv', index=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk mengganti path /kaggle/working ke path dataset yang sudah dibuat\nPRED_INPUT_DIR = Path(\"/kaggle/input/hasil-segmentasi-2/results (2)/predicted_masks\")\n\ndef update_predseg_paths_from_input(df, pred_input_dir=PRED_INPUT_DIR):\n    \"\"\"\n    Untuk tiap base di df, cari file <base>-predseg.nii di pred_input_dir.\n    Jika ada, set df['pred_seg_path'] = str(path). Jika tidak ada, set ke \"\" (kosong).\n    Fungsi tidak membuat file baru, hanya update/overwrite kolom pred_seg_path.\n    \"\"\"\n    pred_input_dir = Path(pred_input_dir)\n    pred_map = {}\n\n    # buat set base unik untuk efisiensi\n    bases = df['filename'].apply(lambda x: str(x).rsplit('-', 1)[0]).unique()\n\n    for base in tqdm(bases, desc=\"Mapping existing predicted masks\"):\n        candidate = pred_input_dir / f\"{base}-predseg.nii\"\n        if candidate.exists():\n            pred_map[base] = str(candidate)\n        else:\n            # kalau tidak ada, kosongkan / atau bisa biarkan nilai lama\n            pred_map[base] = \"\"\n\n    # terapkan ke semua baris (tidak menambah kolom baru, langsung menimpa/isi kolom `pred_seg_path`)\n    df['pred_seg_path'] = df['filename'].apply(lambda fn: pred_map.get(str(fn).rsplit('-', 1)[0], \"\"))\n\n    return df\n\ntrain_df = update_predseg_paths_from_input(train_df)\nval_df   = update_predseg_paths_from_input(validation_df)\ntest_df  = update_predseg_paths_from_input(test_df)\n\n# simpan kembali ke CSV — ini hanya menulis CSV, bukan membuat predseg baru\ntrain_df.to_csv('train_dataset_rebalanced_with_predseg.csv', index=False)\nval_df.to_csv('val_dataset_rebalanced_with_predseg.csv', index=False)\ntest_df.to_csv('test_dataset_rebalanced_with_predseg.csv', index=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load csv\ncsv_path = \"/kaggle/input/hasil-segmentasi-2/results (2)/train_dataset_rebalanced_with_predseg.csv\"\ntrain_df = pd.read_csv(csv_path)\n\n# Fungsi untuk visualisasi\ndef pick_and_show_sample(df, slice_idx=None, force_new=False):\n    global _SELECTED_SAMPLE\n    if force_new or '_SELECTED_SAMPLE' not in globals():\n        _SELECTED_SAMPLE = df.sample(1).iloc[0]\n        print(\"New random sample selected:\", _SELECTED_SAMPLE['filename'])\n    else:\n        print(\"Using cached sample:\", _SELECTED_SAMPLE['filename'])\n    row = _SELECTED_SAMPLE\n    img = np.nan_to_num(nib.load(row['image_path']).get_fdata())\n    mask = np.nan_to_num(nib.load(row['segmentation_path']).get_fdata())\n    num_slices = img.shape[2]\n    if slice_idx is None:\n        slice_idx = num_slices // 2\n    img_slice = img[:, :, slice_idx]\n    mask_slice = mask[:, :, slice_idx]\n    if img_slice.max() > img_slice.min():\n        norm_img = (img_slice - img_slice.min()) / (img_slice.max() - img_slice.min() + 1e-8)\n    else:\n        norm_img = np.zeros_like(img_slice)\n    img_rgb = np.stack([norm_img]*3, axis=-1)\n    mask_bin = (mask_slice > 0).astype(float)\n    overlay = img_rgb.copy()\n    overlay[:, :, 0] += mask_bin * 0.5\n    overlay = np.clip(overlay, 0, 1)\n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    axes[0].imshow(img_rgb)\n    axes[0].set_title(\"Original Image\")\n    axes[1].imshow(mask_bin, cmap='gray')\n    axes[1].set_title(\"Mask\")\n    axes[2].imshow(overlay)\n    axes[2].set_title(\"Overlay\")\n    for ax in axes:\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\npick_and_show_sample(train_df, force_new=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pick_and_show_sample(train_df, slice_idx=50, force_new=True) ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pick_and_show_sample(train_df, slice_idx=65) ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pick_and_show_sample(train_df, slice_idx=77) #(slice tengah biasanya di slice 77)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T13:34:57.408Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predicted Segmentation Policy","metadata":{}},{"cell_type":"code","source":"# Fungsi menghitung dice bin karena ada beberapa predicted segmentation yang jelek, jika jelek pakai Ground Truth segmentation\ndef dice_bin(a, b, eps=1e-6):\n    a = (a > 0).astype(np.uint8)\n    b = (b > 0).astype(np.uint8)\n    inter = np.sum(a * b)\n    return (2 * inter) / (np.sum(a) + np.sum(b) + eps)\n\ndef compute_dice_map(df):\n    if 'base' not in df.columns:\n        df['base'] = df['filename'].apply(lambda x: str(x).rsplit('-', 1)[0])\n    bases = sorted(df['base'].unique())\n    dice_map = {}\n    for base in tqdm(bases, desc=\"Compute dice per base\"):\n        rows = df[df['base']==base]\n        pred = next((p for p in rows['pred_seg_path'].fillna(\"\").tolist() if p), \"\")\n        gt = next((g for g in rows['segmentation_path'].fillna(\"\").tolist() if g), \"\")\n        if pred and gt and Path(pred).exists() and Path(gt).exists():\n            try:\n                a = nib.load(pred).get_fdata().astype(np.uint8)\n                b = nib.load(gt).get_fdata().astype(np.uint8)\n                dice_map[base] = float(dice_bin(a,b)) if a.shape==b.shape else np.nan\n            except Exception:\n                dice_map[base] = np.nan\n        else:\n            dice_map[base] = np.nan\n    return dice_map\n\ndef apply_pred_vs_gt_policy(df, threshold=0.6, show_summary=True):\n    \"\"\"\n    Update df['pred_seg_path'] in-place according to policy:\n      - compute dice per base when both pred & gt exist and shapes match\n      - if dice < threshold -> use GT (segmentation_path) as pred_seg_path (if GT exists)\n      - else keep pred (if exists)\n      - if neither exists -> empty string\n\n    Returns updated df (same object) and dice_map (dict base->dice or np.nan)\n    \"\"\"\n    # ensure base column exists or compute it\n    if 'base' not in df.columns:\n        df['base'] = df['filename'].apply(lambda x: str(x).rsplit('-', 1)[0])\n\n    bases = sorted(df['base'].unique())\n    dice_map = {}\n    replaced_bases = []\n    kept_bases = []\n    missing_bases = []\n\n    for base in tqdm(bases, desc=\"Computing dice per base\"):\n        rows_base = df[df['base'] == base]\n        # pick first non-empty pred and gt for this base (if any)\n        pred = \"\"\n        gt = \"\"\n        # prefer non-empty strings and paths that exist\n        for p in rows_base['pred_seg_path'].fillna(\"\").unique():\n            if p:\n                pred = str(p)\n                break\n        for g in rows_base['segmentation_path'].fillna(\"\").unique():\n            if g:\n                gt = str(g)\n                break\n\n        # normalize to Path for existence check\n        pred_path = Path(pred) if pred else None\n        gt_path = Path(gt) if gt else None\n\n        if pred_path and pred_path.exists() and gt_path and gt_path.exists():\n            try:\n                a = nib.load(str(pred_path)).get_fdata()\n                b = nib.load(str(gt_path)).get_fdata()\n            except Exception as e:\n                # unreadable file -> mark as nan\n                dice_map[base] = np.nan\n                missing_bases.append(base)\n                continue\n\n            if a.shape == b.shape:\n                d = float(dice_bin(a, b))\n                dice_map[base] = d\n            else:\n                dice_map[base] = np.nan\n            # apply policy\n            if not np.isnan(dice_map[base]) and dice_map[base] < threshold:\n                # prefer GT if available\n                df.loc[df['base'] == base, 'pred_seg_path'] = str(gt_path)\n                replaced_bases.append(base)\n            else:\n                # dice >= threshold -> keep pred (no-op)\n                kept_bases.append(base)\n        else:\n            # missing either pred or gt\n            dice_map[base] = np.nan\n            # If GT exists but pred missing -> set pred_seg_path to GT\n            if gt_path and gt_path.exists():\n                df.loc[df['base'] == base, 'pred_seg_path'] = str(gt_path)\n                replaced_bases.append(base)\n            elif pred_path and pred_path.exists():\n                # only pred exists -> keep it\n                kept_bases.append(base)\n            else:\n                # neither exists -> set empty\n                df.loc[df['base'] == base, 'pred_seg_path'] = \"\"\n                missing_bases.append(base)\n\n    if show_summary:\n        total = len(bases)\n        print(f\"Total bases evaluated: {total}\")\n        print(f\"Kept pred (dice >= {threshold} or only pred exists): {len(kept_bases)}\")\n        print(f\"Replaced by GT (dice < {threshold} or pred missing but GT exists): {len(replaced_bases)}\")\n        print(f\"No mask available (neither pred nor GT): {len(missing_bases)}\")\n        # optional: some dice stats (exclude nan)\n        dice_vals = [v for v in dice_map.values() if not np.isnan(v)]\n        if len(dice_vals) > 0:\n            print(f\"Dice stats on computed bases: mean {np.mean(dice_vals):.3f}, median {np.median(dice_vals):.3f}, count {len(dice_vals)}\")\n        else:\n            print(\"No valid dice values computed (no pairs with both files and matching shapes).\")\n\n    return df, dice_map\n    \n# Fungsi Policy untuk Menentukan Segmentation yang akan Digunakan\ndef apply_policy_overwrite_pred_with_gt(df, dice_map, threshold=0.6, verbose=True):\n    if 'base' not in df.columns:\n        df['base'] = df['filename'].apply(lambda x: str(x).rsplit('-',1)[0])\n    for base, d in dice_map.items():\n        rows_base = (df['base'] == base)\n        if not np.isnan(d):\n            if d < threshold:\n                gt = df.loc[rows_base, 'segmentation_path'].fillna(\"\").iloc[0] if any(df.loc[rows_base,'segmentation_path'].fillna(\"\")!=\"\") else \"\"\n                if gt and Path(gt).exists():\n                    df.loc[rows_base, 'pred_seg_path'] = gt\n        else:\n            # fallback: if pred missing but GT exists -> set pred to GT\n            pred_exists = any(df.loc[rows_base,'pred_seg_path'].fillna(\"\")!=\"\")\n            gt_exists = any(df.loc[rows_base,'segmentation_path'].fillna(\"\")!=\"\")\n            if (not pred_exists) and gt_exists:\n                gt = df.loc[rows_base, 'segmentation_path'].fillna(\"\").iloc[0]\n                if gt and Path(gt).exists():\n                    df.loc[rows_base, 'pred_seg_path'] = gt\n    if verbose:\n        vals = [v for v in dice_map.values() if not np.isnan(v)]\n        if vals:\n            print(f\"Dice computed for {len(vals)} bases (mean={np.mean(vals):.3f}, median={np.median(vals):.3f})\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:54.231442Z","iopub.execute_input":"2025-12-08T02:37:54.232192Z","iopub.status.idle":"2025-12-08T02:37:54.255802Z","shell.execute_reply.started":"2025-12-08T02:37:54.232154Z","shell.execute_reply":"2025-12-08T02:37:54.254729Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# # Penggunaan\n# train_df, train_dice_map = apply_pred_vs_gt_policy(train_df, threshold=0.6)\n# train_df.to_csv('train_dataset_rebalanced_with_predseg.csv', index=False)\n\n# # validation/test\n# validation_df, val_dice_map = apply_pred_vs_gt_policy(validation_df, threshold=0.6)\n# validation_df.to_csv('val_dataset_rebalanced_with_predseg.csv', index=False)\n\n# test_df, test_dice_map = apply_pred_vs_gt_policy(test_df, threshold=0.6)\n# test_df.to_csv('test_dataset_rebalanced_with_predseg.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:54.257130Z","iopub.execute_input":"2025-12-08T02:37:54.257408Z","iopub.status.idle":"2025-12-08T02:37:54.280501Z","shell.execute_reply.started":"2025-12-08T02:37:54.257382Z","shell.execute_reply":"2025-12-08T02:37:54.279622Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Tentukan base path ke folder hasil Anda\nbase_path = \"/kaggle/input/hasil-segmentasi-2/\"\n\n# Definisikan nama file\ntrain_file = \"train_dataset_rebalanced_with_predseg (12).csv\"\nval_file = \"val_dataset_rebalanced_with_predseg (2).csv\"\ntest_file = \"test_dataset_rebalanced_with_predseg (3).csv\"\n\n# Load dataset dari file CSV\n\ntrain_df = pd.read_csv(os.path.join(base_path, train_file))\nvalidation_df = pd.read_csv(os.path.join(base_path, val_file))\ntest_df = pd.read_csv(os.path.join(base_path, test_file))\n    \nprint(\"Berhasil me-load train_df, validation_df, dan test_df dari file CSV.\")\nprint(f\"Jumlah data train: {len(train_df)}\")\nprint(f\"Jumlah data validasi: {len(validation_df)}\")\nprint(f\"Jumlah data test: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:54.281604Z","iopub.execute_input":"2025-12-08T02:37:54.281965Z","iopub.status.idle":"2025-12-08T02:37:54.339785Z","shell.execute_reply.started":"2025-12-08T02:37:54.281922Z","shell.execute_reply":"2025-12-08T02:37:54.338838Z"}},"outputs":[{"name":"stdout","text":"Berhasil me-load train_df, validation_df, dan test_df dari file CSV.\nJumlah data train: 280\nJumlah data validasi: 92\nJumlah data test: 96\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:54.341070Z","iopub.execute_input":"2025-12-08T02:37:54.341375Z","iopub.status.idle":"2025-12-08T02:37:54.362916Z","shell.execute_reply.started":"2025-12-08T02:37:54.341346Z","shell.execute_reply":"2025-12-08T02:37:54.362191Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                  filename                                         image_path  \\\n0  BraTS-GLI-00106-000-t1c  /kaggle/input/brats2023-part-1/BraTS-GLI-00106...   \n1  BraTS-GLI-00106-000-t1n  /kaggle/input/brats2023-part-1/BraTS-GLI-00106...   \n2  BraTS-GLI-00106-000-t2f  /kaggle/input/brats2023-part-1/BraTS-GLI-00106...   \n3  BraTS-GLI-00106-000-t2w  /kaggle/input/brats2023-part-1/BraTS-GLI-00106...   \n4  BraTS-GLI-00024-000-t1c  /kaggle/input/brats2023-part-1/BraTS-GLI-00024...   \n\n                                             caption category  \\\n0  Post-contrast T1-weighted images reveal promin...      GLI   \n1  There is an irregular lesion in the right fron...      GLI   \n2  On FLAIR sequence, the lesion shows high signa...      GLI   \n3  The lesion in the right frontal lobe displays ...      GLI   \n4  The lesion demonstrates ring-enhancement post-...      GLI   \n\n                                   segmentation_path  \\\n0  /kaggle/input/brats2023-part-1/BraTS-GLI-00106...   \n1  /kaggle/input/brats2023-part-1/BraTS-GLI-00106...   \n2  /kaggle/input/brats2023-part-1/BraTS-GLI-00106...   \n3  /kaggle/input/brats2023-part-1/BraTS-GLI-00106...   \n4  /kaggle/input/brats2023-part-1/BraTS-GLI-00024...   \n\n                                       pred_seg_path                 base  \n0  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00106-000  \n1  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00106-000  \n2  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00106-000  \n3  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00106-000  \n4  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00024-000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>image_path</th>\n      <th>caption</th>\n      <th>category</th>\n      <th>segmentation_path</th>\n      <th>pred_seg_path</th>\n      <th>base</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BraTS-GLI-00106-000-t1c</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00106...</td>\n      <td>Post-contrast T1-weighted images reveal promin...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00106...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00106-000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BraTS-GLI-00106-000-t1n</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00106...</td>\n      <td>There is an irregular lesion in the right fron...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00106...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00106-000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BraTS-GLI-00106-000-t2f</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00106...</td>\n      <td>On FLAIR sequence, the lesion shows high signa...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00106...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00106-000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BraTS-GLI-00106-000-t2w</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00106...</td>\n      <td>The lesion in the right frontal lobe displays ...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00106...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00106-000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BraTS-GLI-00024-000-t1c</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00024...</td>\n      <td>The lesion demonstrates ring-enhancement post-...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00024...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00024-000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"validation_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:54.365050Z","iopub.execute_input":"2025-12-08T02:37:54.365356Z","iopub.status.idle":"2025-12-08T02:37:54.376506Z","shell.execute_reply.started":"2025-12-08T02:37:54.365327Z","shell.execute_reply":"2025-12-08T02:37:54.375602Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                  filename                                         image_path  \\\n0  BraTS-GLI-00686-000-t1c  /kaggle/input/brats2023-part-1/BraTS-GLI-00686...   \n1  BraTS-GLI-00686-000-t1n  /kaggle/input/brats2023-part-1/BraTS-GLI-00686...   \n2  BraTS-GLI-00686-000-t2f  /kaggle/input/brats2023-part-1/BraTS-GLI-00686...   \n3  BraTS-GLI-00686-000-t2w  /kaggle/input/brats2023-part-1/BraTS-GLI-00686...   \n4  BraTS-GLI-00488-000-t1c  /kaggle/input/brats2023-part-1/BraTS-GLI-00488...   \n\n                                             caption category  \\\n0  Post-contrast T1-weighted images reveal signif...      GLI   \n1  In the right frontal, temporal, and insular lo...      GLI   \n2  On FLAIR images, the lesion in the right front...      GLI   \n3  The lesion in the right frontal, temporal, and...      GLI   \n4  After contrast administration, the lesion in t...      GLI   \n\n                                   segmentation_path  \\\n0  /kaggle/input/brats2023-part-1/BraTS-GLI-00686...   \n1  /kaggle/input/brats2023-part-1/BraTS-GLI-00686...   \n2  /kaggle/input/brats2023-part-1/BraTS-GLI-00686...   \n3  /kaggle/input/brats2023-part-1/BraTS-GLI-00686...   \n4  /kaggle/input/brats2023-part-1/BraTS-GLI-00488...   \n\n                                       pred_seg_path                 base  \n0  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00686-000  \n1  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00686-000  \n2  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00686-000  \n3  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00686-000  \n4  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00488-000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>image_path</th>\n      <th>caption</th>\n      <th>category</th>\n      <th>segmentation_path</th>\n      <th>pred_seg_path</th>\n      <th>base</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BraTS-GLI-00686-000-t1c</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00686...</td>\n      <td>Post-contrast T1-weighted images reveal signif...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00686...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00686-000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BraTS-GLI-00686-000-t1n</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00686...</td>\n      <td>In the right frontal, temporal, and insular lo...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00686...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00686-000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BraTS-GLI-00686-000-t2f</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00686...</td>\n      <td>On FLAIR images, the lesion in the right front...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00686...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00686-000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BraTS-GLI-00686-000-t2w</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00686...</td>\n      <td>The lesion in the right frontal, temporal, and...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00686...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00686-000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BraTS-GLI-00488-000-t1c</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00488...</td>\n      <td>After contrast administration, the lesion in t...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00488...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00488-000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:54.389019Z","iopub.execute_input":"2025-12-08T02:37:54.389719Z","iopub.status.idle":"2025-12-08T02:37:54.399756Z","shell.execute_reply.started":"2025-12-08T02:37:54.389693Z","shell.execute_reply":"2025-12-08T02:37:54.398852Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                  filename                                         image_path  \\\n0  BraTS-GLI-00291-000-t1c  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n1  BraTS-GLI-00291-000-t1n  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n2  BraTS-GLI-00291-000-t2f  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n3  BraTS-GLI-00291-000-t2w  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n4  BraTS-GLI-00706-000-t1c  /kaggle/input/brats2023-part-1/BraTS-GLI-00706...   \n\n                                             caption category  \\\n0  The lesions exhibit uneven enhancement post co...      GLI   \n1  Two lesions in the right parietal lobe show is...      GLI   \n2  Two lesions in the right parietal lobe show mi...      GLI   \n3  Two lesions in the right parietal lobe show hi...      GLI   \n4  After contrast administration, the lesion in t...      GLI   \n\n                                   segmentation_path  \\\n0  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n1  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n2  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n3  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n4  /kaggle/input/brats2023-part-1/BraTS-GLI-00706...   \n\n                                       pred_seg_path                 base  \n0  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00291-000  \n1  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00291-000  \n2  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00291-000  \n3  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00291-000  \n4  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00706-000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>image_path</th>\n      <th>caption</th>\n      <th>category</th>\n      <th>segmentation_path</th>\n      <th>pred_seg_path</th>\n      <th>base</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BraTS-GLI-00291-000-t1c</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>The lesions exhibit uneven enhancement post co...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00291-000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BraTS-GLI-00291-000-t1n</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>Two lesions in the right parietal lobe show is...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00291-000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BraTS-GLI-00291-000-t2f</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>Two lesions in the right parietal lobe show mi...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00291-000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BraTS-GLI-00291-000-t2w</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>Two lesions in the right parietal lobe show hi...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00291-000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BraTS-GLI-00706-000-t1c</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00706...</td>\n      <td>After contrast administration, the lesion in t...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00706...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00706-000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Find Keywords","metadata":{}},{"cell_type":"markdown","source":"### Extract Keywords from Segmentation Mask","metadata":{}},{"cell_type":"code","source":"# KEYWORD PAKAI LOKASI\n\ndef extract_mask_keywords(mask_nii_path):\n    # Load NIfTI\n    nii = nib.load(mask_nii_path)\n    seg_vol = nii.get_fdata().astype(int)\n    vox_dims = nii.header.get_zooms()\n    voxel_vol = np.prod(vox_dims)\n\n    keywords = {}\n    solidity = {}\n    eccentricity = {}\n\n    # --- 1. Analisis Per-Kelas (Volume & Bentuk) ---\n    for c in [1, 2, 3]:\n        coords = np.argwhere(seg_vol == c)\n        if len(coords) == 0:\n            continue\n            \n        # Volume\n        cnt = coords.shape[0]\n        vol_cm3 = cnt * voxel_vol / 1000\n        \n        if vol_cm3 < 20: size = \"small\"\n        elif vol_cm3 <= 50: size = \"moderate\"\n        else: size = \"large\"\n\n        keywords[f\"class_{c}_vol\"] = round(vol_cm3, 1)\n        keywords[f\"class_{c}_size\"] = size\n\n        # Shape (Solidity & Eccentricity per slice)\n        sols, eccs = [], []\n        for k in np.unique(coords[:, 2]):\n            mask2d = (seg_vol[:, :, k] == c).astype(int)\n            if mask2d.sum() == 0: continue\n            rp = regionprops(label(mask2d))[0]\n            sols.append(rp.solidity)\n            eccs.append(rp.eccentricity)\n        \n        if sols:\n            solidity[c] = np.mean(sols)\n            keywords[f\"class_{c}_shape\"] = \"compact\" if solidity[c] >= 0.8 else \"irregular\"\n        \n        if eccs:\n            eccentricity[c] = np.mean(eccs)\n            keywords[f\"class_{c}_form\"] = \"rounded\" if eccentricity[c] < 0.7 else \"elongated\"\n\n    # --- 2. Analisis Lokasi (Global Tumor) ---\n    # Menggunakan gabungan seluruh tumor (seg > 0) untuk lokasi\n    tumor_mask = seg_vol > 0\n    \n    if tumor_mask.sum() == 0:\n        keywords['location'] = \"unknown\"\n    else:\n        # Tentukan titik tengah sumbu X\n        x_mid = seg_vol.shape[0] // 2\n        \n        # Hitung voxel di sisi kiri dan kanan IMAGE array\n        # (Asumsi NIfTI standar)\n        image_left_voxels = tumor_mask[:x_mid, :, :].sum()\n        image_right_voxels = tumor_mask[x_mid:, :, :].sum()\n        \n        # Logika Koreksi: Radiological View Flip\n        # Sisi Kanan Image = Sisi Kiri Pasien (Anatomical LEFT)\n        # Sisi Kiri Image  = Sisi Kanan Pasien (Anatomical RIGHT)\n        \n        if image_right_voxels > image_left_voxels * 1.2:\n            loc_str = \"left\"    # Dominan di image kanan -> Pasien Kiri\n        elif image_left_voxels > image_right_voxels * 1.2:\n            loc_str = \"right\"   # Dominan di image kiri -> Pasien Kanan\n        else:\n            loc_str = \"bilateral\" # Tersebar di kedua sisi\n            \n        keywords['location'] = loc_str\n\n    return keywords","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:54.410766Z","iopub.execute_input":"2025-12-08T02:37:54.411052Z","iopub.status.idle":"2025-12-08T02:37:54.426101Z","shell.execute_reply.started":"2025-12-08T02:37:54.411004Z","shell.execute_reply":"2025-12-08T02:37:54.425255Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import pprint\nfrom pathlib import Path\n\n# Tes fungsi \ndf = train_df  \n\n# contoh 10 base unik (kamu bisa ubah jumlahnya)\nsample_bases = df['base'].unique().tolist()[:10]\nprint(\"Contoh bases (N={}):\".format(len(sample_bases)))\nprint(sample_bases)\n\n# pilih index (0..len(sample_bases)-1)\ni = 8\nbase = sample_bases[i]\nprint(\"Memeriksa base:\", base)\n\n# ambil pred path (first non-empty)\nrows = df[df['base']==base]\npred = next((p for p in rows['pred_seg_path'].fillna(\"\").tolist() if p), \"\")\ngt   = next((g for g in rows['segmentation_path'].fillna(\"\").tolist() if g), \"\")\n\nprint(\"pred_seg_path:\", pred)\nprint(\"segmentation_path (GT):\", gt)\n\n# cek keberadaan file\nif pred and Path(pred).exists():\n    print(\"Pred file exists — running extract_mask_keywords(pred)...\")\n    kws_pred = extract_mask_keywords(pred)\n    pprint.pprint(kws_pred)\nelse:\n    print(\"Pred file tidak ada atau kosong — skip extract pred.\")\n\n# opsional: juga cek GT\nif gt and Path(gt).exists():\n    print(\"\\nGT file exists — running extract_mask_keywords(gt)...\")\n    kws_gt = extract_mask_keywords(gt)\n    pprint.pprint(kws_gt)\nelse:\n    print(\"GT file tidak ada atau kosong — skip extract GT.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:54.457612Z","iopub.execute_input":"2025-12-08T02:37:54.458007Z","iopub.status.idle":"2025-12-08T02:37:56.087926Z","shell.execute_reply.started":"2025-12-08T02:37:54.457948Z","shell.execute_reply":"2025-12-08T02:37:56.086903Z"}},"outputs":[{"name":"stdout","text":"Contoh bases (N=10):\n['BraTS-GLI-00106-000', 'BraTS-GLI-00024-000', 'BraTS-GLI-00604-000', 'BraTS-GLI-00734-001', 'BraTS-GLI-00322-000', 'BraTS-GLI-00598-000', 'BraTS-GLI-00397-000', 'BraTS-GLI-00443-000', 'BraTS-GLI-00652-000', 'BraTS-GLI-00478-000']\nMemeriksa base: BraTS-GLI-00652-000\npred_seg_path: /kaggle/input/hasil-segmentasi-2/results (2)/predicted_masks/BraTS-GLI-00652-000-predseg.nii\nsegmentation_path (GT): /kaggle/input/brats2023-part-1/BraTS-GLI-00652-000/BraTS-GLI-00652-000-seg.nii\nPred file exists — running extract_mask_keywords(pred)...\n{'class_1_form': 'elongated',\n 'class_1_shape': 'irregular',\n 'class_1_size': 'moderate',\n 'class_1_vol': 32.4,\n 'class_2_form': 'elongated',\n 'class_2_shape': 'irregular',\n 'class_2_size': 'large',\n 'class_2_vol': 109.0,\n 'class_3_form': 'elongated',\n 'class_3_shape': 'irregular',\n 'class_3_size': 'large',\n 'class_3_vol': 85.6,\n 'location': 'right'}\n\nGT file exists — running extract_mask_keywords(gt)...\n{'class_1_form': 'elongated',\n 'class_1_shape': 'compact',\n 'class_1_size': 'small',\n 'class_1_vol': 16.2,\n 'class_2_form': 'elongated',\n 'class_2_shape': 'irregular',\n 'class_2_size': 'large',\n 'class_2_vol': 139.6,\n 'class_3_form': 'rounded',\n 'class_3_shape': 'irregular',\n 'class_3_size': 'moderate',\n 'class_3_vol': 25.8,\n 'location': 'right'}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Fungsi untuk membuat keyword map per base\ndef build_keywords_map_from_df(df, extractor_fn):\n    bases = sorted(df['base'].unique())\n    kw_map = {}\n    for base in tqdm(bases, desc=\"Extract keywords per base\"):\n        rows = df[df['base']==base]\n        pred = next((p for p in rows['pred_seg_path'].fillna(\"\").tolist() if p), \"\")\n        if pred and Path(pred).exists():\n            try:\n                kws = extractor_fn(pred)\n                kw_map[base] = kws\n            except Exception:\n                kw_map[base] = {}\n        else:\n            kw_map[base] = {}\n    return kw_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:56.089102Z","iopub.execute_input":"2025-12-08T02:37:56.089713Z","iopub.status.idle":"2025-12-08T02:37:56.095620Z","shell.execute_reply.started":"2025-12-08T02:37:56.089683Z","shell.execute_reply":"2025-12-08T02:37:56.094682Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"subset_df = df[df['base'].isin(sample_bases)].copy()\nkw_map_small = build_keywords_map_from_df(subset_df, extract_mask_keywords)\n\n# tampilkan ringkasan\nprint(\"Total bases processed:\", len(kw_map_small))\n# contoh 5 base pertama dengan isi\nimport itertools\nfor base, kws in itertools.islice(kw_map_small.items(), 10):\n    print(\"\\nBase:\", base)\n    if kws:\n        print(\"  keys:\", list(kws.keys()))\n        # tampilkan beberapa nilai penting kalau ada\n        for k in ['class_1_vol','class_1_size','location','class_1_shape','class_1_form']:\n            if k in kws:\n                print(f\"   {k}: {kws[k]}\")\n    else:\n        print(\"  (no keywords found)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:37:56.096780Z","iopub.execute_input":"2025-12-08T02:37:56.097069Z","iopub.status.idle":"2025-12-08T02:38:03.390588Z","shell.execute_reply.started":"2025-12-08T02:37:56.097042Z","shell.execute_reply":"2025-12-08T02:38:03.389593Z"}},"outputs":[{"name":"stderr","text":"Extract keywords per base: 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Total bases processed: 10\n\nBase: BraTS-GLI-00024-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 20.9\n   class_1_size: moderate\n   location: left\n   class_1_shape: irregular\n   class_1_form: elongated\n\nBase: BraTS-GLI-00106-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 13.5\n   class_1_size: small\n   location: right\n   class_1_shape: irregular\n   class_1_form: elongated\n\nBase: BraTS-GLI-00322-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 10.9\n   class_1_size: small\n   location: right\n   class_1_shape: compact\n   class_1_form: elongated\n\nBase: BraTS-GLI-00397-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 28.2\n   class_1_size: moderate\n   location: right\n   class_1_shape: irregular\n   class_1_form: elongated\n\nBase: BraTS-GLI-00443-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 10.7\n   class_1_size: small\n   location: right\n   class_1_shape: irregular\n   class_1_form: elongated\n\nBase: BraTS-GLI-00478-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 16.1\n   class_1_size: small\n   location: right\n   class_1_shape: compact\n   class_1_form: rounded\n\nBase: BraTS-GLI-00598-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 19.7\n   class_1_size: small\n   location: right\n   class_1_shape: irregular\n   class_1_form: elongated\n\nBase: BraTS-GLI-00604-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 36.5\n   class_1_size: moderate\n   location: right\n   class_1_shape: irregular\n   class_1_form: elongated\n\nBase: BraTS-GLI-00652-000\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 32.4\n   class_1_size: moderate\n   location: right\n   class_1_shape: irregular\n   class_1_form: elongated\n\nBase: BraTS-GLI-00734-001\n  keys: ['class_1_vol', 'class_1_size', 'class_1_shape', 'class_1_form', 'class_2_vol', 'class_2_size', 'class_2_shape', 'class_2_form', 'class_3_vol', 'class_3_size', 'class_3_shape', 'class_3_form', 'location']\n   class_1_vol: 30.1\n   class_1_size: moderate\n   location: left\n   class_1_shape: irregular\n   class_1_form: elongated\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# # Fungsi untuk konversi keyword menjadi frasa natural singkat\ndef keywords_to_phrase(kws):\n    if not kws:\n        return \"\"\n    parts = []\n    if 'class_1_size' in kws and 'class_1_vol' in kws:\n        parts.append(f\"a {kws['class_1_size']} lesion (~{kws['class_1_vol']} cm³)\")\n    if 'location' in kws:\n        parts.append(f\"located in the {kws['location']}\")\n    if 'class_1_shape' in kws:\n        parts.append(f\"with {kws['class_1_shape']} morphology\")\n    if 'class_1_form' in kws:\n        parts.append(f\"and {kws['class_1_form']} form\")\n    phrase = \", \".join(parts)\n    return phrase","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:38:03.391631Z","iopub.execute_input":"2025-12-08T02:38:03.391888Z","iopub.status.idle":"2025-12-08T02:38:03.398023Z","shell.execute_reply.started":"2025-12-08T02:38:03.391862Z","shell.execute_reply":"2025-12-08T02:38:03.397091Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# coba beberapa contoh phrase\nfor base in sample_bases[:10]:\n    kws = kw_map_small.get(base, {}) or {}\n    phrase = keywords_to_phrase(kws)\n    print(f\"\\nBase: {base}\")\n    print(\" kws:\", kws)\n    print(\" phrase:\", repr(phrase))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:38:03.409185Z","iopub.execute_input":"2025-12-08T02:38:03.409549Z","iopub.status.idle":"2025-12-08T02:38:03.422730Z","shell.execute_reply.started":"2025-12-08T02:38:03.409501Z","shell.execute_reply":"2025-12-08T02:38:03.421863Z"}},"outputs":[{"name":"stdout","text":"\nBase: BraTS-GLI-00106-000\n kws: {'class_1_vol': 13.5, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 75.9, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 146.0, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}\n phrase: 'a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form'\n\nBase: BraTS-GLI-00024-000\n kws: {'class_1_vol': 20.9, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 76.9, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 9.6, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}\n phrase: 'a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form'\n\nBase: BraTS-GLI-00604-000\n kws: {'class_1_vol': 36.5, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 146.0, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 39.6, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}\n phrase: 'a moderate lesion (~36.5 cm³), located in the right, with irregular morphology, and elongated form'\n\nBase: BraTS-GLI-00734-001\n kws: {'class_1_vol': 30.1, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 87.5, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 40.8, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}\n phrase: 'a moderate lesion (~30.1 cm³), located in the left, with irregular morphology, and elongated form'\n\nBase: BraTS-GLI-00322-000\n kws: {'class_1_vol': 10.9, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 53.1, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'rounded', 'class_3_vol': 30.1, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}\n phrase: 'a small lesion (~10.9 cm³), located in the right, with compact morphology, and elongated form'\n\nBase: BraTS-GLI-00598-000\n kws: {'class_1_vol': 19.7, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 79.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 46.8, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}\n phrase: 'a small lesion (~19.7 cm³), located in the right, with irregular morphology, and elongated form'\n\nBase: BraTS-GLI-00397-000\n kws: {'class_1_vol': 28.2, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 65.8, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 68.1, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}\n phrase: 'a moderate lesion (~28.2 cm³), located in the right, with irregular morphology, and elongated form'\n\nBase: BraTS-GLI-00443-000\n kws: {'class_1_vol': 10.7, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 58.2, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 37.2, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}\n phrase: 'a small lesion (~10.7 cm³), located in the right, with irregular morphology, and elongated form'\n\nBase: BraTS-GLI-00652-000\n kws: {'class_1_vol': 32.4, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 109.0, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 85.6, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}\n phrase: 'a moderate lesion (~32.4 cm³), located in the right, with irregular morphology, and elongated form'\n\nBase: BraTS-GLI-00478-000\n kws: {'class_1_vol': 16.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 73.0, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 34.0, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'rounded', 'location': 'right'}\n phrase: 'a small lesion (~16.1 cm³), located in the right, with compact morphology, and rounded form'\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def inject_keywords_into_caption(original_caption, kw_phrase, method='append'):\n    if not kw_phrase:\n        return original_caption\n    if method == 'integrate':\n        import re\n        sents = re.split(r'(?<=[.!?])\\s+', original_caption.strip())\n        if len(sents) > 1:\n            sents[0] = sents[0].rstrip('.!?') + f\", which is {kw_phrase}.\"\n            return \" \".join(sents)\n        else:\n            return original_caption.rstrip('.') + f\". The segmentation suggests {kw_phrase}.\"\n    else:\n        return original_caption.rstrip('.') + f\". The segmentation suggests {kw_phrase}.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:38:03.438395Z","iopub.execute_input":"2025-12-08T02:38:03.438695Z","iopub.status.idle":"2025-12-08T02:38:03.450204Z","shell.execute_reply.started":"2025-12-08T02:38:03.438648Z","shell.execute_reply":"2025-12-08T02:38:03.449506Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"base = sample_bases[0]\nrows = df[df['base']==base].iloc[0]  # ambil satu row untuk caption dan preview\norig_caption = rows['caption']\nkws = kw_map_small.get(base, {}) or {}\nphrase = keywords_to_phrase(kws)\ninjected_preview = inject_keywords_into_caption(orig_caption, phrase, method='append')\n\nprint(\"Original caption:\\n\", orig_caption)\nprint(\"\\nPhrase to inject:\\n\", phrase)\nprint(\"\\nInjected preview:\\n\", injected_preview)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:38:03.454161Z","iopub.execute_input":"2025-12-08T02:38:03.454766Z","iopub.status.idle":"2025-12-08T02:38:03.465253Z","shell.execute_reply.started":"2025-12-08T02:38:03.454740Z","shell.execute_reply":"2025-12-08T02:38:03.464205Z"}},"outputs":[{"name":"stdout","text":"Original caption:\n Post-contrast T1-weighted images reveal prominent garland-like enhancement of the lesion, with unclear margins.\n\nPhrase to inject:\n a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form\n\nInjected preview:\n Post-contrast T1-weighted images reveal prominent garland-like enhancement of the lesion, with unclear margins. The segmentation suggests a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def prepare_injected_caption_df(df, extractor_fn, threshold=0.6):\n    dice_map = compute_dice_map(df)\n    df = apply_policy_overwrite_pred_with_gt(df, dice_map, threshold=threshold, verbose=True)\n    kw_map = build_keywords_map_from_df(df, extractor_fn)\n    if 'base' not in df.columns:\n        df['base'] = df['filename'].apply(lambda x: str(x).rsplit('-',1)[0])\n    injected = []\n    for _, row in df.iterrows():\n        base = row['base']\n        kws = kw_map.get(base, {}) or {}\n        phrase = keywords_to_phrase(kws)\n        newcap = inject_keywords_into_caption(str(row['caption']), phrase, method='append')\n        injected.append(newcap)\n    df['caption_injected'] = injected\n    return df, dice_map, kw_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:38:03.466385Z","iopub.execute_input":"2025-12-08T02:38:03.466742Z","iopub.status.idle":"2025-12-08T02:38:03.478357Z","shell.execute_reply.started":"2025-12-08T02:38:03.466716Z","shell.execute_reply":"2025-12-08T02:38:03.477595Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Create injected captions","metadata":{}},{"cell_type":"code","source":"# prepare\nthreshold = 0.6\ndf_prepared, dice_map, kw_map = prepare_injected_caption_df(train_df.copy(), extract_mask_keywords, threshold=threshold)\n# agar mudah inspeksi, simpan juga df_prepared sebagai train_prepared\ntrain_prepared = df_prepared\nprint(\"Done. Rows:\", len(train_prepared))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:38:03.479407Z","iopub.execute_input":"2025-12-08T02:38:03.479717Z","iopub.status.idle":"2025-12-08T02:39:05.128247Z","shell.execute_reply.started":"2025-12-08T02:38:03.479672Z","shell.execute_reply":"2025-12-08T02:39:05.127382Z"}},"outputs":[{"name":"stderr","text":"Compute dice per base: 100%|██████████| 70/70 [00:20<00:00,  3.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dice computed for 70 bases (mean=0.827, median=0.853)\n","output_type":"stream"},{"name":"stderr","text":"Extract keywords per base: 100%|██████████| 70/70 [00:40<00:00,  1.72it/s]","output_type":"stream"},{"name":"stdout","text":"Done. Rows: 280\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\n\n# dice summary\ndice_vals = [v for v in dice_map.values() if not np.isnan(v)]\nprint(\"Bases total:\", len(dice_map))\nprint(\"Dice computed (non-nan):\", len(dice_vals))\nif dice_vals:\n    print(\"  mean: {:.3f}, median: {:.3f}, min: {:.3f}, max: {:.3f}\".format(np.mean(dice_vals), np.median(dice_vals), np.min(dice_vals), np.max(dice_vals)))\n\n# bases with dice < threshold\nlow_dice_bases = [b for b,v in dice_map.items() if (not np.isnan(v)) and (v < threshold)]\nprint(\"Bases with dice < {:.2f}: {}\".format(threshold, len(low_dice_bases)))\n\n# how many bases have no dice computed (nan)\nnan_bases = [b for b,v in dice_map.items() if np.isnan(v)]\nprint(\"Bases with no dice (nan):\", len(nan_bases))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:39:05.129677Z","iopub.execute_input":"2025-12-08T02:39:05.130321Z","iopub.status.idle":"2025-12-08T02:39:05.138412Z","shell.execute_reply.started":"2025-12-08T02:39:05.130276Z","shell.execute_reply":"2025-12-08T02:39:05.137396Z"}},"outputs":[{"name":"stdout","text":"Bases total: 70\nDice computed (non-nan): 70\n  mean: 0.827, median: 0.853, min: 0.614, max: 1.000\nBases with dice < 0.60: 0\nBases with no dice (nan): 0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Train Preparation & Finetuning","metadata":{}},{"cell_type":"code","source":"# load model + tokenizer + feature_extractor\n\nimport os\nfrom pathlib import Path\nimport random\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import VisionEncoderDecoderModel, AutoTokenizer, ViTFeatureExtractor, Trainer, TrainingArguments\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", DEVICE)\nos.environ[\"WANDB_DISABLED\"] = \"true\" \nMODEL_DIR = \"/kaggle/input/3dvit-biomedbert/tfjs/default/1/image caption model/model\"\nTOKENIZER_DIR = \"/kaggle/input/3dvit-biomedbert/tfjs/default/1/image caption model/tokenizer\"\nFEATURE_EXTRACTOR_DIR = \"/kaggle/input/3dvit-biomedbert/tfjs/default/1/image caption model/model\"\nT5_OUT_DIR = \"./t5_edit_model\"   \nRESULTS_DIR = Path.cwd()\nRESULTS_DIR.mkdir(exist_ok=True)\n\nprint(\"Loading model/tokenizer/feature_extractor\")\nvision_model = VisionEncoderDecoderModel.from_pretrained(MODEL_DIR).to(DEVICE)\nvision_tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_DIR)\nfeature_extractor = ViTFeatureExtractor.from_pretrained(FEATURE_EXTRACTOR_DIR)\n\n# config / generation defaults\nvision_model.config.decoder_start_token_id = vision_tokenizer.cls_token_id if vision_tokenizer.cls_token_id is not None else vision_tokenizer.bos_token_id\nvision_model.config.pad_token_id = vision_tokenizer.pad_token_id\nvision_model.config.eos_token_id = vision_tokenizer.eos_token_id\nvision_model.config.max_length = 64\nvision_model.config.num_beams = 4\n\nprint(\"Model loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:39:05.151546Z","iopub.execute_input":"2025-12-08T02:39:05.151812Z","iopub.status.idle":"2025-12-08T02:39:16.623566Z","shell.execute_reply.started":"2025-12-08T02:39:05.151785Z","shell.execute_reply":"2025-12-08T02:39:16.622422Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nLoading model/tokenizer/feature_extractor\n","output_type":"stream"},{"name":"stderr","text":"The following encoder weights were not tied to the decoder ['vision_encoder_decoder/layernorm', 'vision_encoder_decoder/embeddings', 'vision_encoder_decoder/encoder', 'vision_encoder_decoder/pooler']\nThe following encoder weights were not tied to the decoder ['vision_encoder_decoder/layernorm', 'vision_encoder_decoder/embeddings', 'vision_encoder_decoder/encoder', 'vision_encoder_decoder/pooler']\nThe following encoder weights were not tied to the decoder ['vision_encoder_decoder/layernorm', 'vision_encoder_decoder/embeddings', 'vision_encoder_decoder/encoder', 'vision_encoder_decoder/pooler']\n","output_type":"stream"},{"name":"stdout","text":"Model loaded.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport nibabel as nib\n\ndef nifti_to_pil_slice(nifti_path, slice_idx=None, normalize=True):\n    \"\"\"Load NIfTI, pick slice (center jika None), return PIL.Image (uint8 grayscale).\"\"\"\n    img = nib.load(str(nifti_path)).get_fdata()\n    # ensure 3D: if 4D, pick first volume\n    if img.ndim == 4:\n        img = img[..., 0]\n    if img.ndim != 3:\n        raise ValueError(f\"Unsupported nii shape: {img.shape}\")\n    z = img.shape[2]\n    if slice_idx is None:\n        slice_idx = z // 2\n    sl = np.array(img[:, :, slice_idx], dtype=float)\n    if normalize:\n        mn, mx = sl.min(), sl.max()\n        if mx > mn:\n            sl = (sl - mn) / (mx - mn)\n        else:\n            sl = sl * 0.0\n    # convert to 0-255 uint8\n    arr = (sl * 255).astype(np.uint8)\n    pil = Image.fromarray(arr)\n    # convert to RGB if feature_extractor expects 3-channel\n    if pil.mode != \"RGB\":\n        pil = pil.convert(\"RGB\")\n    return pil\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:39:16.624881Z","iopub.execute_input":"2025-12-08T02:39:16.625179Z","iopub.status.idle":"2025-12-08T02:39:16.635771Z","shell.execute_reply.started":"2025-12-08T02:39:16.625150Z","shell.execute_reply":"2025-12-08T02:39:16.634442Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def generate_captions_from_df_safe(df, vision_model, feature_extractor, vision_tokenizer,\n                                   image_col='image_path', out_col='caption_generated',\n                                   batch_size=8, slice_idx=None, device=None):\n    if device is None:\n        device = DEVICE\n    vision_model = vision_model.to(device)\n    vision_model.eval()\n    generated = []\n    paths = df[image_col].tolist()\n    for i in tqdm(range(0, len(paths), batch_size), desc=\"Generating captions\"):\n        batch_paths = paths[i:i+batch_size]\n        imgs = []\n        for p in batch_paths:\n            try:\n                pil = nifti_to_pil_slice(p, slice_idx=slice_idx)\n                imgs.append(pil)\n            except Exception:\n                imgs.append(None)\n        imgs_input = [im for im in imgs if im is not None]\n        if len(imgs_input) == 0:\n            generated.extend([\"\"]*len(imgs)); continue\n        enc = feature_extractor(images=imgs_input, return_tensors=\"pt\")\n        pixel_values = enc['pixel_values'].to(device)\n        with torch.no_grad():\n            out = vision_model.generate(pixel_values=pixel_values,\n                                        max_length=getattr(vision_model.config,'max_length',64),\n                                        num_beams=getattr(vision_model.config,'num_beams',4))\n        decoded = vision_tokenizer.batch_decode(out, skip_special_tokens=True)\n        it = iter(decoded)\n        for im in imgs:\n            generated.append(\"\" if im is None else next(it))\n    df[out_col] = generated\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:39:16.637415Z","iopub.execute_input":"2025-12-08T02:39:16.638226Z","iopub.status.idle":"2025-12-08T02:39:16.654094Z","shell.execute_reply.started":"2025-12-08T02:39:16.638189Z","shell.execute_reply":"2025-12-08T02:39:16.652880Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_df = generate_captions_from_df_safe(train_df, vision_model, feature_extractor, vision_tokenizer, \n                                          image_col='image_path', out_col='caption_generated', batch_size=4)\n\ntrain_df[['filename','caption_generated']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:39:16.655125Z","iopub.execute_input":"2025-12-08T02:39:16.655472Z","iopub.status.idle":"2025-12-08T02:42:00.917574Z","shell.execute_reply.started":"2025-12-08T02:39:16.655408Z","shell.execute_reply":"2025-12-08T02:42:00.916659Z"}},"outputs":[{"name":"stderr","text":"Generating captions:   0%|          | 0/70 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1375: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\nGenerating captions: 100%|██████████| 70/70 [02:44<00:00,  2.35s/it]\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                  filename                                  caption_generated\n0  BraTS-GLI-00106-000-t1c  after contrast administration, the lesion in t...\n1  BraTS-GLI-00106-000-t1n  in the right basal ganglia and insular - tempo...\n2  BraTS-GLI-00106-000-t2f  on flair imaging, the lesion in the right fron...\n3  BraTS-GLI-00106-000-t2w  the lesion in the right frontal lobe shows hig...\n4  BraTS-GLI-00024-000-t1c  after contrast administration, the lesion in t...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>caption_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BraTS-GLI-00106-000-t1c</td>\n      <td>after contrast administration, the lesion in t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BraTS-GLI-00106-000-t1n</td>\n      <td>in the right basal ganglia and insular - tempo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BraTS-GLI-00106-000-t2f</td>\n      <td>on flair imaging, the lesion in the right fron...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BraTS-GLI-00106-000-t2w</td>\n      <td>the lesion in the right frontal lobe shows hig...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BraTS-GLI-00024-000-t1c</td>\n      <td>after contrast administration, the lesion in t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"validation_df = generate_captions_from_df_safe(validation_df, vision_model, feature_extractor, vision_tokenizer, \n                                          image_col='image_path', out_col='caption_generated', batch_size=4)\n\n# quick peek\nvalidation_df[['filename','caption_generated']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T02:42:00.918723Z","iopub.execute_input":"2025-12-08T02:42:00.919038Z","iopub.status.idle":"2025-12-08T02:42:55.675611Z","shell.execute_reply.started":"2025-12-08T02:42:00.918995Z","shell.execute_reply":"2025-12-08T02:42:55.674587Z"}},"outputs":[{"name":"stderr","text":"Generating captions: 100%|██████████| 23/23 [00:54<00:00,  2.38s/it]\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                  filename                                  caption_generated\n0  BraTS-GLI-00686-000-t1c  after contrast administration, the lesion in t...\n1  BraTS-GLI-00686-000-t1n  in the right basal ganglia and insular - tempo...\n2  BraTS-GLI-00686-000-t2f  on flair sequence, the lesion in the right bas...\n3  BraTS-GLI-00686-000-t2w  the lesion in the right frontal lobe shows a m...\n4  BraTS-GLI-00488-000-t1c  after contrast administration, the lesion in t...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>caption_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BraTS-GLI-00686-000-t1c</td>\n      <td>after contrast administration, the lesion in t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BraTS-GLI-00686-000-t1n</td>\n      <td>in the right basal ganglia and insular - tempo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BraTS-GLI-00686-000-t2f</td>\n      <td>on flair sequence, the lesion in the right bas...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BraTS-GLI-00686-000-t2w</td>\n      <td>the lesion in the right frontal lobe shows a m...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BraTS-GLI-00488-000-t1c</td>\n      <td>after contrast administration, the lesion in t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"train_kw_map = build_keywords_map_from_df(train_prepared, extract_mask_keywords)\nprint(train_kw_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:17:27.791634Z","iopub.execute_input":"2025-12-08T04:17:27.792024Z","iopub.status.idle":"2025-12-08T04:18:09.185305Z","shell.execute_reply.started":"2025-12-08T04:17:27.791992Z","shell.execute_reply":"2025-12-08T04:18:09.184422Z"}},"outputs":[{"name":"stderr","text":"Extract keywords per base: 100%|██████████| 70/70 [00:41<00:00,  1.69it/s]","output_type":"stream"},{"name":"stdout","text":"{'BraTS-GLI-00006-000': {'class_1_vol': 52.1, 'class_1_size': 'large', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 71.8, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 30.3, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00017-000': {'class_1_vol': 20.4, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 62.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 7.1, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00021-000': {'class_1_vol': 0.9, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 81.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 6.8, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'right'}, 'BraTS-GLI-00024-000': {'class_1_vol': 20.9, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 76.9, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 9.6, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00045-001': {'class_1_vol': 0.6, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 15.0, 'class_2_size': 'small', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 14.5, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00046-000': {'class_1_vol': 0.8, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 26.2, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 6.8, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'right'}, 'BraTS-GLI-00053-000': {'class_1_vol': 42.6, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 73.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 13.1, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00061-000': {'class_1_vol': 3.7, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 10.2, 'class_2_size': 'small', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 5.6, 'class_3_size': 'small', 'class_3_shape': 'irregular', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00061-001': {'class_1_vol': 1.4, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 26.4, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 7.9, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00064-000': {'class_1_vol': 22.7, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 74.5, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 14.4, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00072-001': {'class_1_vol': 0.9, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 21.4, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 17.3, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00101-000': {'class_1_vol': 3.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 27.7, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 30.4, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00104-000': {'class_1_vol': 3.6, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 29.2, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 40.8, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00106-000': {'class_1_vol': 13.5, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 75.9, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 146.0, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00108-000': {'class_1_vol': 4.4, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 47.0, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 27.1, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00110-000': {'class_1_vol': 12.5, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 54.9, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 38.0, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00134-000': {'class_1_vol': 15.3, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 67.9, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 100.4, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00150-000': {'class_1_vol': 20.4, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 105.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 51.2, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00155-000': {'class_1_vol': 1.9, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 24.9, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 9.8, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00156-000': {'class_1_vol': 27.1, 'class_1_size': 'moderate', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 45.8, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 53.6, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00158-000': {'class_1_vol': 35.7, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 59.2, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 59.6, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00159-000': {'class_1_vol': 18.1, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 51.3, 'class_2_size': 'large', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 32.1, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00184-000': {'class_1_vol': 8.0, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 49.8, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 16.8, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00186-000': {'class_1_vol': 24.0, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 83.3, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 27.3, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00188-000': {'class_1_vol': 9.0, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 20.8, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'rounded', 'class_3_vol': 34.4, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00191-000': {'class_1_vol': 23.1, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 76.2, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 30.1, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00193-000': {'class_1_vol': 0.6, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 24.7, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 40.7, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'bilateral'}, 'BraTS-GLI-00196-000': {'class_1_vol': 13.6, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 65.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 34.3, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00206-000': {'class_1_vol': 0.2, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 18.3, 'class_2_size': 'small', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 32.1, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00218-000': {'class_1_vol': 0.4, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 8.0, 'class_2_size': 'small', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 4.6, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00228-000': {'class_1_vol': 1.2, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 32.3, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 17.8, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00242-000': {'class_1_vol': 10.6, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 44.0, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 41.4, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00247-000': {'class_1_vol': 12.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 81.5, 'class_2_size': 'large', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 43.1, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00283-000': {'class_1_vol': 4.9, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 40.0, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 21.8, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00285-000': {'class_1_vol': 0.0, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 5.6, 'class_2_size': 'small', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 3.7, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00293-000': {'class_1_vol': 0.2, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 32.9, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 8.6, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00310-000': {'class_1_vol': 18.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 34.8, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 46.4, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'rounded', 'location': 'right'}, 'BraTS-GLI-00322-000': {'class_1_vol': 10.9, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 53.1, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'rounded', 'class_3_vol': 30.1, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00336-000': {'class_1_vol': 35.4, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 81.4, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 31.3, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00341-000': {'class_1_vol': 0.5, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 11.1, 'class_2_size': 'small', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 6.2, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00390-000': {'class_1_vol': 0.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 16.5, 'class_2_size': 'small', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 0.4, 'class_3_size': 'small', 'class_3_shape': 'irregular', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00397-000': {'class_1_vol': 28.2, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 65.8, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 68.1, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00400-000': {'class_1_vol': 32.3, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 96.4, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 24.7, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00401-000': {'class_1_vol': 42.3, 'class_1_size': 'moderate', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 69.9, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 27.4, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00416-000': {'class_1_vol': 34.7, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 96.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 78.0, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00430-000': {'class_1_vol': 8.1, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'rounded', 'class_2_vol': 41.2, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 16.1, 'class_3_size': 'small', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00443-000': {'class_1_vol': 10.7, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 58.2, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 37.2, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00444-000': {'class_1_vol': 0.0, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 3.7, 'class_2_size': 'small', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 16.7, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00453-000': {'class_1_vol': 3.0, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 25.2, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 28.8, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00456-000': {'class_1_vol': 55.8, 'class_1_size': 'large', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 102.0, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 53.2, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00478-000': {'class_1_vol': 16.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 73.0, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 34.0, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'rounded', 'location': 'right'}, 'BraTS-GLI-00480-001': {'class_1_vol': 8.7, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 38.4, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 44.8, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00491-001': {'class_1_vol': 12.4, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 54.1, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 40.9, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00511-001': {'class_1_vol': 30.4, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 76.4, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 62.9, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00514-001': {'class_1_vol': 12.4, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 79.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 45.5, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00520-000': {'class_1_vol': 3.4, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 31.4, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'rounded', 'class_3_vol': 6.3, 'class_3_size': 'small', 'class_3_shape': 'irregular', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00547-000': {'class_1_vol': 4.0, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 43.2, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 9.1, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00559-000': {'class_1_vol': 31.9, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 96.3, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 24.5, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00598-000': {'class_1_vol': 19.7, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 79.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 46.8, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00599-000': {'class_1_vol': 28.0, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 63.1, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 39.1, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00604-000': {'class_1_vol': 36.5, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 146.0, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 39.6, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00607-001': {'class_1_vol': 5.7, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 42.0, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 9.8, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00623-000': {'class_1_vol': 8.7, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 73.3, 'class_2_size': 'large', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 10.3, 'class_3_size': 'small', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00652-000': {'class_1_vol': 32.4, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 109.0, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 85.6, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00680-000': {'class_1_vol': 9.2, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 68.1, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 17.8, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00694-001': {'class_1_vol': 0.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 107.2, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 0.7, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'right'}, 'BraTS-GLI-00715-001': {'class_1_vol': 1.5, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 30.1, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 47.7, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00716-000': {'class_1_vol': 3.3, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 29.6, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'rounded', 'class_3_vol': 9.6, 'class_3_size': 'small', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00725-001': {'class_1_vol': 0.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 124.6, 'class_2_size': 'large', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 2.2, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'bilateral'}, 'BraTS-GLI-00734-001': {'class_1_vol': 30.1, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 87.5, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 40.8, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":210},{"cell_type":"code","source":"def remove_location_words(text):\n    return re.sub(r'\\b(left|right|bilateral)\\b', '[LOC]', text, flags=re.IGNORECASE)\n\n# Prepare dataset for T5 fine-tuning (edit task)\ndef build_train_examples_from_df(df, kw_map):\n    inputs, targets = [], []\n    for _, row in df.iterrows():\n        base = row['base']\n        kws = kw_map.get(base, {}) or {}\n        phrase = keywords_to_phrase(kws)\n        clean_vit_caption = remove_location_words(row['caption_generated'])\n        \n        # Prompt structure\n        src = f\"refine: {clean_vit_caption.strip()} Keywords: {phrase}\"\n        # src = f\"Constraints: {phrase}. Refine this caption to match constraints: {clean_vit_caption.strip()}\"\n        tgt = row['caption_injected'].strip()\n        \n        inputs.append(src)\n        targets.append(tgt)\n    return inputs, targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:36:55.797252Z","iopub.execute_input":"2025-12-08T04:36:55.798223Z","iopub.status.idle":"2025-12-08T04:36:55.804523Z","shell.execute_reply.started":"2025-12-08T04:36:55.798182Z","shell.execute_reply":"2025-12-08T04:36:55.803519Z"}},"outputs":[],"execution_count":278},{"cell_type":"code","source":"# Fine-tune T5 (small) with HuggingFace Trainer\ndef fine_tune_t5(train_inputs, train_targets, val_inputs=None, val_targets=None,\n                 model_name=\"t5-small\", out_dir=\"./t5_edit_model\", \n                 num_train_epochs=5,  \n                 per_device_train_batch_size=8, \n                 per_device_eval_batch_size=8,\n                 learning_rate=3e-4,  \n                 warmup_steps=500,    \n                 weight_decay=0.01,   \n                 load_best_model_at_end=True,\n                 metric_for_best_model=\"eval_loss\",\n                 save_total_limit=3): \n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)  \n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n    model.resize_token_embeddings(len(tokenizer))\n    \n    # tokenization\n    def preprocess(examples):\n        model_inputs = tokenizer(examples[\"input\"], max_length=256, truncation=True, padding=\"max_length\")\n        with tokenizer.as_target_tokenizer():\n            labels = tokenizer(examples[\"target\"], max_length=256, truncation=True, padding=\"max_length\")\n        \n        labels_ids = np.array(labels[\"input_ids\"])\n        labels_ids[labels_ids == tokenizer.pad_token_id] = -100\n    \n        model_inputs[\"labels\"] = labels_ids.tolist()\n        return model_inputs\n\n    from datasets import Dataset, DatasetDict\n    train_ds = Dataset.from_dict({\"input\": train_inputs, \"target\": train_targets})\n    val_ds = Dataset.from_dict({\"input\": val_inputs, \"target\": val_targets}) if (val_inputs and val_targets) else None\n\n    tokenized_train = train_ds.map(preprocess, batched=True, remove_columns=[\"input\", \"target\"])\n    tokenized_val = val_ds.map(preprocess, batched=True, remove_columns=[\"input\", \"target\"]) if val_ds else None\n\n    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n    training_args = Seq2SeqTrainingArguments(\n        output_dir=out_dir,\n        num_train_epochs=num_train_epochs,\n        learning_rate=learning_rate,\n        per_device_train_batch_size=per_device_train_batch_size,\n        per_device_eval_batch_size=per_device_eval_batch_size,\n        warmup_steps=warmup_steps,\n        weight_decay=weight_decay,\n        evaluation_strategy=\"epoch\" if tokenized_val else \"no\", # Logika lama dipertahankan\n        save_strategy=\"epoch\",\n        load_best_model_at_end=load_best_model_at_end,\n        metric_for_best_model=metric_for_best_model,\n        predict_with_generate=True,\n        logging_strategy=\"steps\",\n        logging_steps=50,\n        fp16=torch.cuda.is_available(),\n        save_total_limit=save_total_limit\n    )\n    # ----------------------------------------------------\n\n    trainer = Seq2SeqTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_train,\n        eval_dataset=tokenized_val if tokenized_val else None,\n        tokenizer=tokenizer,\n        data_collator=data_collator\n    )\n\n    trainer.train()\n    trainer.save_model(out_dir)\n    return out_dir, tokenizer, model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:37:12.905474Z","iopub.execute_input":"2025-12-08T04:37:12.905836Z","iopub.status.idle":"2025-12-08T04:37:12.917710Z","shell.execute_reply.started":"2025-12-08T04:37:12.905807Z","shell.execute_reply":"2025-12-08T04:37:12.916883Z"}},"outputs":[],"execution_count":279},{"cell_type":"code","source":"# Prepare injected captions (policy + extraction)\ntrain_df, train_dice_map, train_kw_map = prepare_injected_caption_df(train_df, extract_mask_keywords, threshold=0.6)\nvalidation_df, val_dice_map, val_kw_map = prepare_injected_caption_df(validation_df, extract_mask_keywords, threshold=0.6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:31:22.144922Z","iopub.execute_input":"2025-12-08T04:31:22.145291Z","iopub.status.idle":"2025-12-08T04:32:26.721028Z","shell.execute_reply.started":"2025-12-08T04:31:22.145261Z","shell.execute_reply":"2025-12-08T04:32:26.720028Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Compute dice per base:   0%|          | 0/70 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c96f58bfdcc49dcbc1c52e390ed097b"}},"metadata":{}},{"name":"stdout","text":"Dice computed for 70 bases (mean=0.827, median=0.853)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extract keywords per base:   0%|          | 0/70 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1c220906a8b4ac6ad9bc834d67ec379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Compute dice per base:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b35553ed099d4db68a48e99dd18bcc15"}},"metadata":{}},{"name":"stdout","text":"Dice computed for 23 bases (mean=0.818, median=0.814)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extract keywords per base:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c52bcf433474791a47376f2028e67e4"}},"metadata":{}}],"execution_count":270},{"cell_type":"code","source":"# Build train examples for T5\ntrain_inputs, train_targets = build_train_examples_from_df(train_df, train_kw_map)\nval_inputs, val_targets = build_train_examples_from_df(validation_df, val_kw_map)\n\nfor i in range(10):\n    print(\"SRC:\", train_inputs[i])\n    print(\"TGT:\", train_targets[i])\n    print(\"---\")\n    \n# quick statistics\nempty_src = sum(1 for s in train_inputs if not s.strip())\nempty_tgt = sum(1 for t in train_targets if not t.strip())\nprint(\"Train pairs:\", len(train_inputs), \"empty src:\", empty_src, \"empty tgt:\", empty_tgt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:37:26.240840Z","iopub.execute_input":"2025-12-08T04:37:26.241225Z","iopub.status.idle":"2025-12-08T04:37:26.276727Z","shell.execute_reply.started":"2025-12-08T04:37:26.241190Z","shell.execute_reply":"2025-12-08T04:37:26.275732Z"}},"outputs":[{"name":"stdout","text":"SRC: refine: after contrast administration, the lesion in the [LOC] frontal lobe shows marked ring - like enhancement, with unclear, and measures approximately 12 * 12 * 73. is accompanied by a breakdown in size of the blood - like area of the [LOC] lateral ventricle, and is associated with no mention of the midline structures. Keywords: a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form\nTGT: Post-contrast T1-weighted images reveal prominent garland-like enhancement of the lesion, with unclear margins. The segmentation suggests a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form.\n---\nSRC: refine: in the [LOC] basal ganglia and insular - temporal lobe, there is an irregular lesion with isointense to low signal, indistinct boundaries, on t1 - weighted images, and surrounding brain parenchyma edema is present. the [LOC] lateral ventricle exhibiting isointensity, with no displacement of the midline structures, and Keywords: a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form\nTGT: There is an irregular lesion in the right frontal lobe exhibiting mainly low signal intensity with some high signal areas on T1-weighted images. The lesion measures approximately 78*117*78 mm, has unclear boundaries, and is causing compression of the right lateral ventricle, with leftward shift of midline structures. The segmentation suggests a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form.\n---\nSRC: refine: on flair imaging, the lesion in the [LOC] frontal lobe shows mixed high and low signal intensities, with significant surrounding edema., midline structures, and no mention of alteration in sulci, gyri, ventricles, and cisterns of abnormalities are noted. is noted in the midline structures, Keywords: a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form\nTGT: On FLAIR sequence, the lesion shows high signal intensity and is associated with significant surrounding brain edema. The segmentation suggests a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form.\n---\nSRC: refine: the lesion in the [LOC] frontal lobe shows high signal intensity on t2 - weighted images, with extensive surrounding edema. there is no displacement of the midline in the midline structures, sulci, gyri, ventricles, and no mention of alteration to the midline shift observed. is no evidence of the sulci Keywords: a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form\nTGT: The lesion in the right frontal lobe displays high signal intensity on T2-weighted images, with extensive edema evident in the surrounding brain parenchyma. The segmentation suggests a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form.\n---\nSRC: refine: after contrast administration, the lesion in the [LOC] frontal lobe shows marked ring - like enhancement on t1c, suggesting active lesion. the presence of a, there is a breakdown of a blood - brain barrier breakdown in the blood - defined boundaries and possible breakdown of the lesion is no mention of the midline structures, Keywords: a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form\nTGT: The lesion demonstrates ring-enhancement post-contrast on T1-weighted images, suggesting active lesion characteristics with unclear borders. The segmentation suggests a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form.\n---\nSRC: refine: the lesion located in the anterior interhemispheric fissure appears isointense on t1w mri sequence, with surrounding brain tissue showing extensive edema. there is compression of the midline structures, and no mention of the report does not specify the sulci, gyri, ventricles, and cisterns of the [LOC] lateral Keywords: a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form\nTGT: The lesion located in the left temporal lobe appears slightly hypointense on T1-weighted images with an approximate size of 53*81*65 mm, presenting unclear boundaries and no evident impact on midline structures. The segmentation suggests a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form.\n---\nSRC: refine: on the flair sequence, the lesion in the [LOC] temporal lobe presents with mixed high and low signal intensity. there is extensive surrounding brain parenchyma edema edema in the midline structures, there is no mention of the sulci, gyri, ventricles, and there is a large areas of the lesion's no Keywords: a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form\nTGT: The lesion located in the left temporal lobe exhibits high signal intensity on FLAIR images, indicating some mixed signals within the lesion and brain tissue edema without effect on the midline structures. The segmentation suggests a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form.\n---\nSRC: refine: the lesion in the [LOC] frontal lobe shows mixed high and low signal intensity on t2 - weighted images. there is extensive surrounding brain parenchyma showing extensive edema on the midline structures, and no mention of the sulci, gyri, and there is a large area of a large areas of the midline shift observed. Keywords: a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form\nTGT: The lesion located in the left temporal lobe appears hyperintense on T2-weighted images with surrounding brain tissue edema, with no shift of the midline structures. The segmentation suggests a moderate lesion (~20.9 cm³), located in the left, with irregular morphology, and elongated form.\n---\nSRC: refine: after contrast administration, the lesion in the [LOC] frontal lobe shows marked ring - like enhancement on t1 - weighted imaging. the boundaries of the lesion are in the surrounding brain barrier, there is an isointense signal intensity and [LOC] lateral ventricle exhibiting a large area of high signal intensity on t1w imaging. Keywords: a moderate lesion (~36.5 cm³), located in the right, with irregular morphology, and elongated form\nTGT: An irregular abnormal signal focus in the right frontal lobe showing inhomogeneously enhanced signal on contrast-enhanced T1-weighted imaging with multiple vessel shadows within. The segmentation suggests a moderate lesion (~36.5 cm³), located in the right, with irregular morphology, and elongated form.\n---\nSRC: refine: in the [LOC] basal ganglia and insular - temporal lobe, there is an irregular lesion with isointense to low signal, indistinct boundaries, on t1 - weighted images, measuring approximately 12 * 43 * 15 * 15 mm in the surrounding brain parenchyma showing a significant surrounding brain tissue showing significant edema, measuring Keywords: a moderate lesion (~36.5 cm³), located in the right, with irregular morphology, and elongated form\nTGT: An irregular abnormal signal focus in the right frontal lobe with low signal on T1-weighted imaging, displaying indistinct boundaries, accompanied by local high signal intensities, and showing surrounding brain parenchyma edema. The right lateral ventricle is compressed, with displacement of the midline structures to the left. The segmentation suggests a moderate lesion (~36.5 cm³), located in the right, with irregular morphology, and elongated form.\n---\nTrain pairs: 280 empty src: 0 empty tgt: 0\n","output_type":"stream"}],"execution_count":280},{"cell_type":"code","source":"# Verify format\nprint(\"=== VERIFY NEW FORMAT ===\")\nprint(\"Input example:\")\nprint(train_inputs[0])\nprint(\"\\nTarget example:\")\nprint(train_targets[0])\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:37:35.556752Z","iopub.execute_input":"2025-12-08T04:37:35.557415Z","iopub.status.idle":"2025-12-08T04:37:35.562516Z","shell.execute_reply.started":"2025-12-08T04:37:35.557380Z","shell.execute_reply":"2025-12-08T04:37:35.561515Z"}},"outputs":[{"name":"stdout","text":"=== VERIFY NEW FORMAT ===\nInput example:\nrefine: after contrast administration, the lesion in the [LOC] frontal lobe shows marked ring - like enhancement, with unclear, and measures approximately 12 * 12 * 73. is accompanied by a breakdown in size of the blood - like area of the [LOC] lateral ventricle, and is associated with no mention of the midline structures. Keywords: a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form\n\nTarget example:\nPost-contrast T1-weighted images reveal prominent garland-like enhancement of the lesion, with unclear margins. The segmentation suggests a small lesion (~13.5 cm³), located in the right, with irregular morphology, and elongated form.\n\n","output_type":"stream"}],"execution_count":281},{"cell_type":"code","source":"# BARU\nout_dir, t5_tokenizer, t5_model = fine_tune_t5(\n    train_inputs, train_targets, \n    val_inputs, val_targets,\n    model_name=\"t5-small\", \n    out_dir=\"./t5_edit_model\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:37:41.046274Z","iopub.execute_input":"2025-12-08T04:37:41.046655Z","iopub.status.idle":"2025-12-08T04:38:32.563485Z","shell.execute_reply.started":"2025-12-08T04:37:41.046623Z","shell.execute_reply":"2025-12-08T04:38:32.562389Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/280 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da0fec4894c74b428263d42f8d401b9a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/92 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb4f482b205a44bbae9d2e2853f05c1f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [90/90 00:48, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>2.863690</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>2.561599</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.870500</td>\n      <td>2.210345</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.870500</td>\n      <td>1.940326</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.870500</td>\n      <td>1.734925</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThere were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"}],"execution_count":282},{"cell_type":"code","source":"# === KODE DEBUGGING UNTUK VERIFIKASI DATA PELATIHAN T5 ===\nprint(\"--- Memeriksa Data Pelatihan (TRAIN) ---\")\n# Pastikan train_inputs dan train_targets ada dan tidak kosong\nif 'train_inputs' in locals() and len(train_inputs) > 0:\n    print(f\"Total data pelatihan: {len(train_inputs)}\")\n    # Ambil 3 contoh acak\n    for i in sorted(random.sample(range(len(train_inputs)), 3)):\n        print(f\"\\n[Contoh Train {i}]\")\n        print(f\"  SRC (Input T5): \\n    {repr(train_inputs[i])}\")\n        print(f\"  TGT (Target T5): \\n    {repr(train_targets[i])}\")\nelse:\n    print(\"ERROR: 'train_inputs' tidak ditemukan atau kosong.\")\n\nprint(\"\\n--- Memeriksa Data Validasi (VALIDATION) ---\")\n# Periksa juga data validasi\nif 'val_inputs' in locals() and len(val_inputs) > 0:\n    print(f\"Total data validasi: {len(val_inputs)}\")\n    # Ambil 1 contoh acak\n    i = random.randint(0, len(val_inputs) - 1)\n    print(f\"\\n[Contoh Val {i}]\")\n    print(f\"  SRC (Input T5): \\n    {repr(val_inputs[i])}\")\n    print(f\"  TGT (Target T5): \\n    {repr(val_targets[i])}\")\nelse:\n    print(\"ERROR: 'val_inputs' tidak ditemukan atau kosong.\")\n# ==========================================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:34:21.622741Z","iopub.execute_input":"2025-12-08T04:34:21.623044Z","iopub.status.idle":"2025-12-08T04:34:21.630481Z","shell.execute_reply.started":"2025-12-08T04:34:21.623015Z","shell.execute_reply":"2025-12-08T04:34:21.629674Z"}},"outputs":[{"name":"stdout","text":"--- Memeriksa Data Pelatihan (TRAIN) ---\nTotal data pelatihan: 757\n\n[Contoh Train 25]\n  SRC (Input T5): \n    'refine: on flair sequence, the lesion in the [LOC] frontal lobe and basal ganglia region shows mixed high and low signal intensities. there is extensive surrounding brain to the midline structures show a large areas of high signal intensities, and a large area of edema in the report does not described in the sulci, and low Keywords: a moderate lesion (~28.2 cm³), located in the right, with irregular morphology, and elongated form'\n  TGT (Target T5): \n    'On the T1W sequence, there are irregular foci with mixed high and low signal intensities in the right frontal-parietal-temporal-occipital lobes and bilateral periventricular areas. The lesion, measuring approximately 81*96*82mm, crosses the midline, associated with significant surrounding edema, compression of the right lateral ventricle, and deviation of midline structures to the left. The segmentation suggests a moderate lesion (~28.2 cm³), located in the right, with irregular morphology, and elongated form.'\n\n[Contoh Train 114]\n  SRC (Input T5): \n    'refine: high signal intensity is observed in the abnormal signal focus within the [LOC] frontal lobe on flair imaging, indicating the presence of an abnormal signal. to the lesion measures approximately 46 * 12 * 47 * 35 mm in the midline structures, measuring approximately 12 * 45 mm in size, and no mention of the Keywords: a small lesion (~0.4 cm³), located in the left, with irregular morphology, and elongated form'\n  TGT (Target T5): \n    'High signal intensity is observed in the abnormal signal focus within the left frontal lobe on FLAIR imaging, with an indistinct boundary, measuring about 32*43*35mm; slight swelling of the surrounding soft tissue is present, without displacement of the midline. The segmentation suggests a small lesion (~0.4 cm³), located in the left, with irregular morphology, and elongated form.'\n\n[Contoh Train 654]\n  SRC (Input T5): \n    'refine: in the [LOC] frontal lobe, there is an irregular abnormal signal focus with low signal intensity, indistinct boundaries, accompanied by a slight surrounding brain, measuring approximately 46 * 15 * 15mm in the lesion measures approximately 12 * 12 mm, presenting as a slight hyperintense signal. there is no mention of Keywords: a small lesion (~0.5 cm³), located in the left, with compact morphology, and rounded form'\n  TGT (Target T5): \n    'The left parietal lobe shows an irregular lesion with low T1 signal intensity, measuring approximately 37*46*46 mm, with indefinite boundaries. There is no shift of midline structures. The segmentation suggests a small lesion (~0.5 cm³), located in the left, with compact morphology, and rounded form.'\n\n--- Memeriksa Data Validasi (VALIDATION) ---\nTotal data validasi: 92\n\n[Contoh Val 35]\n  SRC (Input T5): \n    'refine: the lesion in the [LOC] frontal lobe shows mixed high and low signal intensity on t2 - weighted images, with surrounding brain parenchyma showing extensive edema. there in the midline structures show a large amount of a large area of the lesion.. is associated with a large surrounding brain parenchymal edema is observed. Keywords: a moderate lesion (~23.1 cm³), located in the right, with compact morphology, and elongated form'\n  TGT (Target T5): \n    'There is an irregular abnormal signal focus in the right frontal lobe crossing the midline. It manifests as a mixed high signal area on T2W imaging, indicating variation in tissue composition or stage. There is significant surrounding edema. The segmentation suggests a moderate lesion (~23.1 cm³), located in the right, with compact morphology, and elongated form.'\n","output_type":"stream"}],"execution_count":274},{"cell_type":"markdown","source":"## Inference & Evaluation","metadata":{}},{"cell_type":"code","source":"test_kw_map = build_keywords_map_from_df(test_df, extract_mask_keywords)\nprint(test_kw_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:38:32.566356Z","iopub.execute_input":"2025-12-08T04:38:32.566751Z","iopub.status.idle":"2025-12-08T04:38:46.657853Z","shell.execute_reply.started":"2025-12-08T04:38:32.566716Z","shell.execute_reply":"2025-12-08T04:38:46.655040Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Extract keywords per base:   0%|          | 0/24 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5539c039a48481dbdc1d965c3586c49"}},"metadata":{}},{"name":"stdout","text":"{'BraTS-GLI-00012-000': {'class_1_vol': 125.1, 'class_1_size': 'large', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 115.3, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 22.4, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00032-001': {'class_1_vol': 7.6, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'rounded', 'class_2_vol': 82.2, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 49.4, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00121-000': {'class_1_vol': 0.7, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 48.1, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 17.9, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00122-000': {'class_1_vol': 0.8, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 15.4, 'class_2_size': 'small', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 51.3, 'class_3_size': 'large', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00140-000': {'class_1_vol': 0.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 14.0, 'class_2_size': 'small', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 2.6, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00187-000': {'class_1_vol': 10.7, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 82.9, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 50.9, 'class_3_size': 'large', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00237-000': {'class_1_vol': 3.7, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 24.6, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 15.3, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00291-000': {'class_1_vol': 0.5, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 40.7, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 47.6, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00314-000': {'class_1_vol': 1.2, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 15.0, 'class_2_size': 'small', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 12.9, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'right'}, 'BraTS-GLI-00316-000': {'class_1_vol': 1.6, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 24.8, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'rounded', 'class_3_vol': 12.0, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'right'}, 'BraTS-GLI-00320-000': {'class_1_vol': 2.5, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 34.2, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 11.3, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00327-000': {'class_1_vol': 10.0, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 63.2, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 21.2, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00349-000': {'class_1_vol': 1.5, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 46.1, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 57.1, 'class_3_size': 'large', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00360-000': {'class_1_vol': 5.2, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 29.3, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 51.9, 'class_3_size': 'large', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00376-000': {'class_1_vol': 2.0, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 27.2, 'class_2_size': 'moderate', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 13.5, 'class_3_size': 'small', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00445-000': {'class_1_vol': 18.7, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 90.1, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 71.6, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00469-000': {'class_1_vol': 19.0, 'class_1_size': 'small', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 55.0, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 13.7, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00525-001': {'class_1_vol': 15.7, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 62.5, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'rounded', 'class_3_vol': 46.9, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00540-000': {'class_2_vol': 12.3, 'class_2_size': 'small', 'class_2_shape': 'compact', 'class_2_form': 'elongated', 'class_3_vol': 0.2, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'rounded', 'location': 'right'}, 'BraTS-GLI-00542-000': {'class_1_vol': 9.5, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 34.0, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 43.0, 'class_3_size': 'moderate', 'class_3_shape': 'irregular', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00575-000': {'class_1_vol': 14.3, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'elongated', 'class_2_vol': 54.2, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 78.1, 'class_3_size': 'large', 'class_3_shape': 'irregular', 'class_3_form': 'rounded', 'location': 'left'}, 'BraTS-GLI-00590-000': {'class_1_vol': 26.9, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 90.6, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 36.1, 'class_3_size': 'moderate', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}, 'BraTS-GLI-00630-000': {'class_1_vol': 1.1, 'class_1_size': 'small', 'class_1_shape': 'compact', 'class_1_form': 'rounded', 'class_2_vol': 41.1, 'class_2_size': 'moderate', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 19.3, 'class_3_size': 'small', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'left'}, 'BraTS-GLI-00706-000': {'class_1_vol': 30.6, 'class_1_size': 'moderate', 'class_1_shape': 'irregular', 'class_1_form': 'elongated', 'class_2_vol': 100.5, 'class_2_size': 'large', 'class_2_shape': 'irregular', 'class_2_form': 'elongated', 'class_3_vol': 51.0, 'class_3_size': 'large', 'class_3_shape': 'compact', 'class_3_form': 'elongated', 'location': 'right'}}\n","output_type":"stream"}],"execution_count":283},{"cell_type":"code","source":"# 2) Generate baseline captions on test using explicit variables:\ntest_df = generate_captions_from_df_safe(test_df, vision_model, feature_extractor, vision_tokenizer,\n                                             image_col='image_path', out_col='caption_generated', batch_size=4)\n\n# quick peek\ntest_df[['filename','caption_generated']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T03:00:04.917031Z","iopub.execute_input":"2025-12-08T03:00:04.917342Z","iopub.status.idle":"2025-12-08T03:00:04.921402Z","shell.execute_reply.started":"2025-12-08T03:00:04.917315Z","shell.execute_reply":"2025-12-08T03:00:04.920476Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"import re\n\n# 1. Definisi Fungsi Masking/Removal\ndef remove_location_words(text):\n    if not isinstance(text, str): return \"\"\n    # Ganti kata lokasi dengan token netral [LOC] atau hapus saja\n    return re.sub(r'\\b(left|right|bilateral)\\b', '[LOC]', text, flags=re.IGNORECASE)\n\n# 2. Terapkan pada pembuatan T5 source strings\ntest_df['t5_src'] = test_df.apply(\n    lambda r: f\"refine: {remove_location_words(r['caption_generated'])} Keywords: {keywords_to_phrase(test_kw_map.get(r['base'], {}))}\",\n    axis=1\n)\n\n# # Terapkan format BARU: \"Constraints: {keyword}. Refine...: {caption}\"\n# test_df['t5_src'] = test_df.apply(\n#     lambda r: f\"Constraints: {keywords_to_phrase(test_kw_map.get(r['base'], {}))}. Refine this caption to match constraints: {remove_location_words(r['caption_generated']).strip()}\",\n#     axis=1\n# )\n\nt5_tokenizer = AutoTokenizer.from_pretrained(T5_OUT_DIR) # Pastikan class tokenizer sesuai saat training\nt5_model = AutoModelForSeq2SeqLM.from_pretrained(T5_OUT_DIR).to(DEVICE)\nt5_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:38:46.659059Z","iopub.execute_input":"2025-12-08T04:38:46.659486Z","iopub.status.idle":"2025-12-08T04:38:47.065063Z","shell.execute_reply.started":"2025-12-08T04:38:46.659420Z","shell.execute_reply":"2025-12-08T04:38:47.064046Z"}},"outputs":[{"execution_count":284,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32100, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32100, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32100, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32100, bias=False)\n)"},"metadata":{}}],"execution_count":284},{"cell_type":"code","source":"# run T5 inference\ngenerated = []\nbatch_size = 8\n\nfor i in tqdm(range(0, len(test_df), batch_size), desc=\"T5 Inferencing\"):\n    batch = test_df['t5_src'].tolist()[i:i+batch_size]\n    \n    inputs = t5_tokenizer(\n        batch, \n        return_tensors=\"pt\", \n        padding=True, \n        truncation=True, \n        max_length=256\n    ).to(DEVICE)\n    \n    with torch.no_grad():\n        input_tokens = t5_tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n        input_len = input_tokens.input_ids.shape[1]\n        \n        outs = t5_model.generate(\n            **inputs, \n            max_length=int(input_len * 0.7),\n            min_length=20,\n            num_beams=4,\n            length_penalty=0.8,\n            no_repeat_ngram_size=3,\n            early_stopping=True,\n            decoder_start_token_id=t5_tokenizer.pad_token_id,\n            pad_token_id=t5_tokenizer.pad_token_id,\n            eos_token_id=t5_tokenizer.eos_token_id,\n        )\n    \n    dec = t5_tokenizer.batch_decode(outs, skip_special_tokens=True)\n    generated.extend(dec)\n\ntest_df['caption_generated_injected'] = generated","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:38:47.066666Z","iopub.execute_input":"2025-12-08T04:38:47.066933Z","iopub.status.idle":"2025-12-08T04:39:11.814952Z","shell.execute_reply.started":"2025-12-08T04:38:47.066907Z","shell.execute_reply":"2025-12-08T04:39:11.813967Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"T5 Inferencing:   0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af8e37a8696b481d8592b26f5977cbdd"}},"metadata":{}}],"execution_count":285},{"cell_type":"code","source":"def evaluate_corpus(hyps, refs):\n    bleu = sacrebleu.corpus_bleu(hyps, [refs])\n    P, R, F1 = bert_score(hyps, refs, lang='en', rescale_with_baseline=True)\n    sbert = SentenceTransformer('all-mpnet-base-v2')\n    emb_h = sbert.encode(hyps, convert_to_tensor=True)\n    emb_r = sbert.encode(refs, convert_to_tensor=True)\n    cosines = util.cos_sim(emb_h, emb_r).diag().cpu().numpy()\n    return {\"bleu\": float(bleu.score), \"bert_f1_mean\": float(F1.mean().item()), \"sbert_cosine_mean\": float(cosines.mean())}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:16.457108Z","iopub.execute_input":"2025-12-08T04:27:16.457523Z","iopub.status.idle":"2025-12-08T04:27:16.463876Z","shell.execute_reply.started":"2025-12-08T04:27:16.457478Z","shell.execute_reply":"2025-12-08T04:27:16.462970Z"}},"outputs":[],"execution_count":249},{"cell_type":"code","source":"# 4) Evaluate:\nrefs = test_df['caption'].fillna(\"\").tolist()\n\nprint(\"\\n--- 1. HASIL EVALUASI: Baseline (Tahap 1: vision_model) ---\")\nhyps_baseline = test_df['caption_generated'].tolist()\n# Pastikan refs dan hyps memiliki panjang yang sama\nif len(hyps_baseline) == len(refs):\n    metrics_baseline = evaluate_corpus(hyps_baseline, refs)\n    print(metrics_baseline)\nelse:\n    print(f\"Error: Panjang hipotesis ({len(hyps_baseline)}) tidak sama dengan referensi ({len(refs)})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:16.475559Z","iopub.execute_input":"2025-12-08T04:27:16.476107Z","iopub.status.idle":"2025-12-08T04:27:21.331387Z","shell.execute_reply.started":"2025-12-08T04:27:16.476077Z","shell.execute_reply":"2025-12-08T04:27:21.330308Z"}},"outputs":[{"name":"stdout","text":"\n--- 1. HASIL EVALUASI: Baseline (Tahap 1: vision_model) ---\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dea974c9ce2f4874bd81032d878bab8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad48b575d7c442168f5ace8aa1887022"}},"metadata":{}},{"name":"stdout","text":"{'bleu': 12.083650208569985, 'bert_f1_mean': 0.2993832528591156, 'sbert_cosine_mean': 0.7617081999778748}\n","output_type":"stream"}],"execution_count":250},{"cell_type":"code","source":"print(\"\\n--- 2. HASIL EVALUASI: Model Akhir (Tahap 1 + Tahap 2: T5 Editor) ---\")\nhyps_final = test_df['caption_generated_injected'].tolist()\n# Pastikan refs dan hyps memiliki panjang yang sama\nif len(hyps_final) == len(refs):\n    metrics_final = evaluate_corpus(hyps_final, refs)\n    print(metrics_final)\nelse:\n    print(f\"Error: Panjang hipotesis ({len(hyps_final)}) tidak sama dengan referensi ({len(refs)})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:21.333014Z","iopub.execute_input":"2025-12-08T04:27:21.333328Z","iopub.status.idle":"2025-12-08T04:27:26.206858Z","shell.execute_reply.started":"2025-12-08T04:27:21.333298Z","shell.execute_reply":"2025-12-08T04:27:26.205830Z"}},"outputs":[{"name":"stdout","text":"\n--- 2. HASIL EVALUASI: Model Akhir (Tahap 1 + Tahap 2: T5 Editor) ---\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6e3a5cd25fc4008a168c770d544ddda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ded9a0d0e8e24316894fd2381ba6fb25"}},"metadata":{}},{"name":"stdout","text":"{'bleu': 14.180616482283071, 'bert_f1_mean': 0.31815317273139954, 'sbert_cosine_mean': 0.7493132948875427}\n","output_type":"stream"}],"execution_count":251},{"cell_type":"code","source":"print(\"\\nContoh hasil akhir (head):\")\nprint(test_df[['filename', 'caption', 'caption_generated', 't5_src', 'caption_generated_injected']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:26.208241Z","iopub.execute_input":"2025-12-08T04:27:26.208937Z","iopub.status.idle":"2025-12-08T04:27:26.217960Z","shell.execute_reply.started":"2025-12-08T04:27:26.208886Z","shell.execute_reply":"2025-12-08T04:27:26.216886Z"}},"outputs":[{"name":"stdout","text":"\nContoh hasil akhir (head):\n                  filename                                            caption  \\\n0  BraTS-GLI-00291-000-t1c  The lesions exhibit uneven enhancement post co...   \n1  BraTS-GLI-00291-000-t1n  Two lesions in the right parietal lobe show is...   \n2  BraTS-GLI-00291-000-t2f  Two lesions in the right parietal lobe show mi...   \n3  BraTS-GLI-00291-000-t2w  Two lesions in the right parietal lobe show hi...   \n4  BraTS-GLI-00706-000-t1c  After contrast administration, the lesion in t...   \n\n                                   caption_generated  \\\n0  post - contrast t1 - weighted imaging reveals ...   \n1  in the right parietal lobe, there is a mass - ...   \n2  the lesion in the right parietal lobe shows mi...   \n3  the lesion in the right parietal lobe appears ...   \n4  after contrast administration, the lesion in t...   \n\n                                              t5_src  \\\n0  refine: post - contrast t1 - weighted imaging ...   \n1  refine: in the [LOC] parietal lobe, there is a...   \n2  refine: the lesion in the [LOC] parietal lobe ...   \n3  refine: the lesion in the [LOC] parietal lobe ...   \n4  refine: after contrast administration, the les...   \n\n                          caption_generated_injected  \n0  post-contrast t1 - weighted imaging reveals ri...  \n1  In the right parietal lobe, there is a mass - ...  \n2  The lesion in the right parietal lobe shows mi...  \n3  The lesion in the right parietal lobe appears ...  \n4  After contrast administration, the lesion in t...  \n","output_type":"stream"}],"execution_count":252},{"cell_type":"code","source":"# 5) Save results:\ntest_df.to_csv(RESULTS_DIR / \"test_with_generated_injected.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:49:43.745474Z","iopub.execute_input":"2025-12-08T04:49:43.746372Z","iopub.status.idle":"2025-12-08T04:49:43.757569Z","shell.execute_reply.started":"2025-12-08T04:49:43.746332Z","shell.execute_reply":"2025-12-08T04:49:43.756626Z"}},"outputs":[],"execution_count":286},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:26.249053Z","iopub.execute_input":"2025-12-08T04:27:26.249333Z","iopub.status.idle":"2025-12-08T04:27:26.263164Z","shell.execute_reply.started":"2025-12-08T04:27:26.249305Z","shell.execute_reply":"2025-12-08T04:27:26.262228Z"}},"outputs":[{"execution_count":255,"output_type":"execute_result","data":{"text/plain":"                  filename                                         image_path  \\\n0  BraTS-GLI-00291-000-t1c  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n1  BraTS-GLI-00291-000-t1n  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n2  BraTS-GLI-00291-000-t2f  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n3  BraTS-GLI-00291-000-t2w  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n4  BraTS-GLI-00706-000-t1c  /kaggle/input/brats2023-part-1/BraTS-GLI-00706...   \n\n                                             caption category  \\\n0  The lesions exhibit uneven enhancement post co...      GLI   \n1  Two lesions in the right parietal lobe show is...      GLI   \n2  Two lesions in the right parietal lobe show mi...      GLI   \n3  Two lesions in the right parietal lobe show hi...      GLI   \n4  After contrast administration, the lesion in t...      GLI   \n\n                                   segmentation_path  \\\n0  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n1  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n2  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n3  /kaggle/input/brats2023-part-1/BraTS-GLI-00291...   \n4  /kaggle/input/brats2023-part-1/BraTS-GLI-00706...   \n\n                                       pred_seg_path                 base  \\\n0  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00291-000   \n1  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00291-000   \n2  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00291-000   \n3  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00291-000   \n4  /kaggle/input/hasil-segmentasi-2/results (2)/p...  BraTS-GLI-00706-000   \n\n                                   caption_generated  \\\n0  post - contrast t1 - weighted imaging reveals ...   \n1  in the right parietal lobe, there is a mass - ...   \n2  the lesion in the right parietal lobe shows mi...   \n3  the lesion in the right parietal lobe appears ...   \n4  after contrast administration, the lesion in t...   \n\n                                              t5_src  \\\n0  refine: post - contrast t1 - weighted imaging ...   \n1  refine: in the [LOC] parietal lobe, there is a...   \n2  refine: the lesion in the [LOC] parietal lobe ...   \n3  refine: the lesion in the [LOC] parietal lobe ...   \n4  refine: after contrast administration, the les...   \n\n                          caption_generated_injected  \n0  post-contrast t1 - weighted imaging reveals ri...  \n1  In the right parietal lobe, there is a mass - ...  \n2  The lesion in the right parietal lobe shows mi...  \n3  The lesion in the right parietal lobe appears ...  \n4  After contrast administration, the lesion in t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>image_path</th>\n      <th>caption</th>\n      <th>category</th>\n      <th>segmentation_path</th>\n      <th>pred_seg_path</th>\n      <th>base</th>\n      <th>caption_generated</th>\n      <th>t5_src</th>\n      <th>caption_generated_injected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BraTS-GLI-00291-000-t1c</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>The lesions exhibit uneven enhancement post co...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00291-000</td>\n      <td>post - contrast t1 - weighted imaging reveals ...</td>\n      <td>refine: post - contrast t1 - weighted imaging ...</td>\n      <td>post-contrast t1 - weighted imaging reveals ri...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BraTS-GLI-00291-000-t1n</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>Two lesions in the right parietal lobe show is...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00291-000</td>\n      <td>in the right parietal lobe, there is a mass - ...</td>\n      <td>refine: in the [LOC] parietal lobe, there is a...</td>\n      <td>In the right parietal lobe, there is a mass - ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BraTS-GLI-00291-000-t2f</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>Two lesions in the right parietal lobe show mi...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00291-000</td>\n      <td>the lesion in the right parietal lobe shows mi...</td>\n      <td>refine: the lesion in the [LOC] parietal lobe ...</td>\n      <td>The lesion in the right parietal lobe shows mi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BraTS-GLI-00291-000-t2w</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>Two lesions in the right parietal lobe show hi...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00291...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00291-000</td>\n      <td>the lesion in the right parietal lobe appears ...</td>\n      <td>refine: the lesion in the [LOC] parietal lobe ...</td>\n      <td>The lesion in the right parietal lobe appears ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BraTS-GLI-00706-000-t1c</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00706...</td>\n      <td>After contrast administration, the lesion in t...</td>\n      <td>GLI</td>\n      <td>/kaggle/input/brats2023-part-1/BraTS-GLI-00706...</td>\n      <td>/kaggle/input/hasil-segmentasi-2/results (2)/p...</td>\n      <td>BraTS-GLI-00706-000</td>\n      <td>after contrast administration, the lesion in t...</td>\n      <td>refine: after contrast administration, the les...</td>\n      <td>After contrast administration, the lesion in t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":255},{"cell_type":"code","source":"import sacrebleu\nfrom sacrebleu.metrics import BLEU \nfrom bert_score import score as bert_score\nfrom sentence_transformers import SentenceTransformer, util\nimport torch\nimport numpy as np\n\nsbert_model = SentenceTransformer('all-mpnet-base-v2').to(DEVICE) \n\ndef evaluate_corpus_detailed(hyps, refs, device=DEVICE):\n    bleu1_obj = BLEU(max_ngram_order=1)\n    bleu1 = bleu1_obj.corpus_score(hyps, [refs]).score\n    \n    bleu2_obj = BLEU(max_ngram_order=2)\n    bleu2 = bleu2_obj.corpus_score(hyps, [refs]).score\n    \n    bleu3_obj = BLEU(max_ngram_order=3)\n    bleu3 = bleu3_obj.corpus_score(hyps, [refs]).score\n    \n    bleu4_obj = BLEU(max_ngram_order=4)\n    bleu4 = bleu4_obj.corpus_score(hyps, [refs]).score\n    # ---------------------------------\n    \n    P, R, F1 = bert_score(hyps, refs, lang='en', rescale_with_baseline=True, device=device)\n    \n    emb_h = sbert_model.encode(hyps, convert_to_tensor=True, show_progress_bar=False)\n    emb_r = sbert_model.encode(refs, convert_to_tensor=True, show_progress_bar=False)\n    cosines = util.cos_sim(emb_h, emb_r).diag().cpu().numpy()\n\n    return {\n        \"BLEU_corpus\": float(bleu4), \n        \n        \"BLEU1\": float(bleu1),\n        \"BLEU2\": float(bleu2),\n        \"BLEU3\": float(bleu3),\n        \"BLEU4\": float(bleu4),\n        \n        \"BERTScore_F1\": float(F1.mean().item()),\n        \"SBERT_Cosine\": float(cosines.mean())\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:26.264540Z","iopub.execute_input":"2025-12-08T04:27:26.264914Z","iopub.status.idle":"2025-12-08T04:27:27.188658Z","shell.execute_reply.started":"2025-12-08T04:27:26.264873Z","shell.execute_reply":"2025-12-08T04:27:27.187813Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":256},{"cell_type":"code","source":"import pprint\n\n# 4) Evaluate:\nrefs = test_df['caption'].fillna(\"\").tolist()\n\nprint(\"\\n--- 1. HASIL EVALUASI: Baseline (Tahap 1: vision_model) ---\")\nhyps_baseline = test_df['caption_generated'].tolist()\n\nif len(hyps_baseline) == len(refs):\n    metrics_baseline = evaluate_corpus_detailed(hyps_baseline, refs) \n    pprint.pprint(metrics_baseline) \nelse:\n    print(f\"Error: Panjang hipotesis ({len(hyps_baseline)}) tidak sama dengan referensi ({len(refs)})\")\n\nprint(\"\\n--- 2. HASIL EVALUASI: Model Akhir (Tahap 1 + Tahap 2: T5 Editor) ---\")\nhyps_final = test_df['caption_generated_injected'].tolist()\n\nif len(hyps_final) == len(refs):\n    metrics_final = evaluate_corpus_detailed(hyps_final, refs) \n    pprint.pprint(metrics_final) \nelse:\n    print(f\"Error: Panjang hipotesis ({len(hyps_final)}) tidak sama dengan referensi ({len(refs)})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:27.189952Z","iopub.execute_input":"2025-12-08T04:27:27.190262Z","iopub.status.idle":"2025-12-08T04:27:35.299104Z","shell.execute_reply.started":"2025-12-08T04:27:27.190231Z","shell.execute_reply":"2025-12-08T04:27:35.297923Z"}},"outputs":[{"name":"stdout","text":"\n--- 1. HASIL EVALUASI: Baseline (Tahap 1: vision_model) ---\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"{'BERTScore_F1': 0.2993832528591156,\n 'BLEU1': 35.97527722232321,\n 'BLEU2': 23.54651975407515,\n 'BLEU3': 16.4210980605062,\n 'BLEU4': 12.083650208569985,\n 'BLEU_corpus': 12.083650208569985,\n 'SBERT_Cosine': 0.7617081999778748}\n\n--- 2. HASIL EVALUASI: Model Akhir (Tahap 1 + Tahap 2: T5 Editor) ---\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"{'BERTScore_F1': 0.31815317273139954,\n 'BLEU1': 37.53454947484798,\n 'BLEU2': 25.464847374693814,\n 'BLEU3': 18.618058795277936,\n 'BLEU4': 14.180616482283071,\n 'BLEU_corpus': 14.180616482283071,\n 'SBERT_Cosine': 0.7493132948875427}\n","output_type":"stream"}],"execution_count":257},{"cell_type":"code","source":"# Print generated text length distribution\nimport numpy as np\n\nstage1_lens = [len(t.split()) for t in test_df['caption_generated']]\nstage2_lens = [len(t.split()) for t in test_df['caption_generated_injected']]\ngt_lens = [len(t.split()) for t in test_df['caption']]\n\nprint(f\"Ground Truth avg length: {np.mean(gt_lens):.1f} words\")\nprint(f\"Stage 1 avg length:      {np.mean(stage1_lens):.1f} words\")\nprint(f\"Stage 2 avg length:      {np.mean(stage2_lens):.1f} words\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:35.312598Z","iopub.execute_input":"2025-12-08T04:27:35.312947Z","iopub.status.idle":"2025-12-08T04:27:35.325140Z","shell.execute_reply.started":"2025-12-08T04:27:35.312907Z","shell.execute_reply":"2025-12-08T04:27:35.324141Z"}},"outputs":[{"name":"stdout","text":"Ground Truth avg length: 35.3 words\nStage 1 avg length:      51.6 words\nStage 2 avg length:      48.2 words\n","output_type":"stream"}],"execution_count":259},{"cell_type":"code","source":"# Check if T5 just copies input\nfrom difflib import SequenceMatcher\n\nsimilarities = []\nfor _, row in test_df.iterrows():\n    sim = SequenceMatcher(None, \n                          row['caption_generated'], \n                          row['caption_generated_injected']).ratio()\n    similarities.append(sim)\n\navg_sim = np.mean(similarities)\nprint(f\"Avg similarity between Stage 1 and Stage 2: {avg_sim:.2%}\")\n\nif avg_sim > 0.9:\n    print(\"⚠️ WARNING: T5 is mostly copying input without editing!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:35.326221Z","iopub.execute_input":"2025-12-08T04:27:35.326552Z","iopub.status.idle":"2025-12-08T04:27:35.395854Z","shell.execute_reply.started":"2025-12-08T04:27:35.326519Z","shell.execute_reply":"2025-12-08T04:27:35.394880Z"}},"outputs":[{"name":"stdout","text":"Avg similarity between Stage 1 and Stage 2: 74.87%\n","output_type":"stream"}],"execution_count":260},{"cell_type":"code","source":"# Analisis kasus dengan BLEU terendah\nimport pandas as pd\nfrom nltk.translate.bleu_score import sentence_bleu\n\nresults = []\nfor idx, row in test_df.iterrows():\n    ref = [row['caption'].split()]\n    hyp = row['caption_generated_injected'].split()\n    bleu = sentence_bleu(ref, hyp)\n    results.append({\n        'idx': idx,\n        'bleu': bleu,\n        'caption_gen': row['caption_generated'],\n        'caption_injected': row['caption_generated_injected'],\n        'caption_gt': row['caption']\n    })\n\nresults_df = pd.DataFrame(results).sort_values('bleu')\n\nprint(\"=== 10 WORST CASES ===\")\nprint(results_df.head(10))\n\nprint(\"\\n=== 10 BEST CASES ===\")\nprint(results_df.tail(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:35.460325Z","iopub.execute_input":"2025-12-08T04:27:35.461023Z","iopub.status.idle":"2025-12-08T04:27:35.516412Z","shell.execute_reply.started":"2025-12-08T04:27:35.460980Z","shell.execute_reply":"2025-12-08T04:27:35.515525Z"}},"outputs":[{"name":"stdout","text":"=== 10 WORST CASES ===\n    idx      bleu                                        caption_gen  \\\n62   62  0.069977  on flair sequence, the lesion in the right fro...   \n85   85  0.071520  the lesion located in the anterior interhemisp...   \n22   22  0.078574  on flair sequences, the lesion in the left fro...   \n16   16  0.079883  after contrast administration, the lesion demo...   \n32   32  0.080706  after contrast administration, the lesion in t...   \n82   82  0.084669  on flair sequence, the lesion in the right fro...   \n73   73  0.089176  in the right frontal lobe, there is an irregul...   \n78   78  0.089666  on flair sequences, the lesion in the right fr...   \n47   47  0.092100  the lesion in the right frontal lobe shows a m...   \n28   28  0.093506  after contrast administration, the lesion in t...   \n\n                                     caption_injected  \\\n62  On flair sequence, the lesion in the left fron...   \n85  The lesion located in the left anterior interh...   \n22  On flair sequences, the lesion in the left fro...   \n16  After contrast administration, the lesion demo...   \n32  After contrast administration, the lesion in t...   \n82  On flair sequence, the lesion in the right fro...   \n73  In the left frontal lobe, there is an irregula...   \n78  On flair sequences, the lesion in the left fro...   \n47  The lesion in the right frontal lobe shows a m...   \n28  a small lesion (19.0 cm3), located in the left...   \n\n                                           caption_gt  \n62  On FLAIR sequences, the lesion demonstrates mi...  \n85  In the left parietal lobe, there is a lesion e...  \n22  On FLAIR images, the lesion in the left basal ...  \n16  After contrast administration, the lesion show...  \n32  After contrast administration, the lesion demo...  \n82  On FLAIR images, a high signal intensity mass ...  \n73  At the junction of the left frontal and pariet...  \n78  The lesion in the left frontal-temporal lobe s...  \n47  The focus in the right temporal lobe is hyperi...  \n28  Following contrast administration, the lesion ...  \n\n=== 10 BEST CASES ===\n    idx      bleu                                        caption_gen  \\\n81   81  0.368827  in the right frontal lobe, there is a lesion p...   \n75   75  0.383982  the lesion in the right parietal lobe appears ...   \n95   95  0.384957  the lesion in the right frontal lobe shows hig...   \n63   63  0.387934  the lesion in the right frontal lobe shows an ...   \n26   26  0.398486  on flair sequence, the lesion in the right fro...   \n8     8  0.411443  after contrast administration, the lesion in t...   \n70   70  0.490094  on the flair sequence, the lesion in the left ...   \n6     6  0.495233  on flair sequence, the lesion demonstrates a m...   \n67   67  0.571108  the lesion at the junction of the right fronta...   \n57   57  0.600964  the lesion located in the anterior interhemisp...   \n\n                                     caption_injected  \\\n81  In the right frontal lobe, there is a lesion p...   \n75  The lesion in the left parietal lobe appears s...   \n95  The lesion in the right frontal lobe shows hig...   \n63  The lesion in the left frontal lobe shows an i...   \n26  On flair sequence, the lesion in the right fro...   \n8   After contrast administration, the lesion in t...   \n70  On the flair sequence, the lesion in the left ...   \n6   On flair sequence, the lesion demonstrates a m...   \n67  The lesion at the junction of the [LOC] fronta...   \n57  The lesion located in the right, with irregula...   \n\n                                           caption_gt  \n81  On T1-weighted images, a mass with slightly lo...  \n75  The lesion at the junction of the left frontal...  \n95  A slightly hyperintense signal lesion is obser...  \n63  On T2-weighted MRI sequences, the lesion refle...  \n26  On FLAIR sequence, the lesion in the right fro...  \n8   After the administration of contrast, the lesi...  \n70  The abnormal signal focus on FLAIR sequence al...  \n6   On FLAIR sequence, the lesion demonstrates a m...  \n67  On T2-weighted imaging, the lesion demonstrate...  \n57  The right temporal lobe shows an irregular les...  \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 4-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 3-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}],"execution_count":263},{"cell_type":"code","source":"# Check training data distribution\nfrom collections import Counter\n\n# Extract locations from captions\ndef extract_location(caption):\n    # Simple regex untuk detect hemisphere\n    import re\n    if re.search(r'\\bleft\\b', caption.lower()):\n        return 'left'\n    elif re.search(r'\\bright\\b', caption.lower()):\n        return 'right'\n    elif re.search(r'\\bbilateral\\b', caption.lower()):\n        return 'bilateral'\n    return 'unknown'\n\ntrain_locations = [extract_location(cap) for cap in train_df['caption']]\nprint(\"Training data distribution:\")\nprint(Counter(train_locations))\n\ntest_locations = [extract_location(cap) for cap in test_df['caption']]\nprint(\"\\nTest data distribution:\")\nprint(Counter(test_locations))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:35.517845Z","iopub.execute_input":"2025-12-08T04:27:35.518632Z","iopub.status.idle":"2025-12-08T04:27:35.530530Z","shell.execute_reply.started":"2025-12-08T04:27:35.518585Z","shell.execute_reply":"2025-12-08T04:27:35.529660Z"}},"outputs":[{"name":"stdout","text":"Training data distribution:\nCounter({'left': 161, 'right': 89, 'unknown': 23, 'bilateral': 7})\n\nTest data distribution:\nCounter({'left': 58, 'right': 23, 'unknown': 15})\n","output_type":"stream"}],"execution_count":264},{"cell_type":"code","source":"import re\nfrom collections import Counter\n\nprint(\"=== LOCATION ACCURACY EVALUATION ===\\n\")\n\n# Helper function\ndef extract_location_from_text(text):\n    \"\"\"Extract location (left/right/bilateral) from text.\"\"\"\n    text_lower = text.lower()\n    if 'bilateral' in text_lower or ('left' in text_lower and 'right' in text_lower):\n        return 'bilateral'\n    elif 'left' in text_lower:\n        return 'left'\n    elif 'right' in text_lower:\n        return 'right'\n    else:\n        return 'unknown'\n\n# 1. Ground Truth Location Distribution\ngt_locations = [extract_location_from_text(cap) for cap in test_df['caption']]\nprint(\"1. GROUND TRUTH LOCATIONS:\")\nprint(Counter(gt_locations))\n\n# 2. Keyword Location Distribution\nkw_locations = [test_kw_map.get(row['base'], {}).get('location', 'unknown') \n                for _, row in test_df.iterrows()]\nprint(\"\\n2. KEYWORD LOCATIONS (from segmentation):\")\nprint(Counter(kw_locations))\n\n# 3. ViT Prediction Location Distribution\nvit_locations = [extract_location_from_text(cap) for cap in test_df['caption_generated']]\nprint(\"\\n3. ViT PREDICTION LOCATIONS:\")\nprint(Counter(vit_locations))\n\n# 4. T5 Output Location Distribution\nt5_locations = [extract_location_from_text(cap) for cap in test_df['caption_generated_injected']]\nprint(\"\\n4. T5 OUTPUT LOCATIONS (after adding keyword):\")\nprint(Counter(t5_locations))\n\n# 5. Accuracy Metrics\nprint(\"\\n\" + \"=\"*60)\nprint(\"ACCURACY METRICS:\")\nprint(\"=\"*60)\n\n# Keyword vs GT accuracy\nkw_correct = sum(1 for kw, gt in zip(kw_locations, gt_locations) \n                 if kw != 'unknown' and gt != 'unknown' and kw == gt)\nkw_total = sum(1 for kw, gt in zip(kw_locations, gt_locations) \n               if kw != 'unknown' and gt != 'unknown')\nkw_accuracy = kw_correct / kw_total if kw_total > 0 else 0\n\nprint(f\"\\nKeyword Location Accuracy: {kw_correct}/{kw_total} = {kw_accuracy*100:.1f}%\")\n\n# ViT vs GT accuracy\nvit_correct = sum(1 for vit, gt in zip(vit_locations, gt_locations) \n                  if vit != 'unknown' and gt != 'unknown' and vit == gt)\nvit_total = sum(1 for vit, gt in zip(vit_locations, gt_locations) \n                if vit != 'unknown' and gt != 'unknown')\nvit_accuracy = vit_correct / vit_total if vit_total > 0 else 0\n\nprint(f\"ViT Location Accuracy:     {vit_correct}/{vit_total} = {vit_accuracy*100:.1f}%\")\n\n# T5 vs GT accuracy\nt5_correct = sum(1 for t5, gt in zip(t5_locations, gt_locations) \n                 if t5 != 'unknown' and gt != 'unknown' and t5 == gt)\nt5_total = sum(1 for t5, gt in zip(t5_locations, gt_locations) \n               if t5 != 'unknown' and gt != 'unknown')\nt5_accuracy = t5_correct / t5_total if t5_total > 0 else 0\n\nprint(f\"T5 Location Accuracy:      {t5_correct}/{t5_total} = {t5_accuracy*100:.1f}%\")\n\n# 6. Detailed Mismatch Analysis\nprint(\"\\n\" + \"=\"*60)\nprint(\"MISMATCH ANALYSIS:\")\nprint(\"=\"*60)\n\nmismatches = []\nfor idx, row in test_df.iterrows():\n    gt_loc = extract_location_from_text(row['caption'])\n    kw_loc = test_kw_map.get(row['base'], {}).get('location', 'unknown')\n    vit_loc = extract_location_from_text(row['caption_generated'])\n    t5_loc = extract_location_from_text(row['caption_generated_injected'])\n    \n    if gt_loc != 'unknown' and t5_loc != gt_loc:\n        mismatches.append({\n            'idx': idx,\n            'gt': gt_loc,\n            'keyword': kw_loc,\n            'vit': vit_loc,\n            't5': t5_loc,\n            'kw_correct': kw_loc == gt_loc,\n            't5_follows_kw': t5_loc == kw_loc,\n            't5_follows_vit': t5_loc == vit_loc,\n        })\n\nprint(f\"\\nTotal mismatches: {len(mismatches)}/{len(test_df)}\")\n\nif mismatches:\n    print(\"\\nFirst 10 mismatches:\")\n    print(f\"{'Idx':<5} {'GT':<10} {'Keyword':<10} {'ViT':<10} {'T5':<10} {'KW✓':<6} {'T5→KW':<8} {'T5→ViT':<8}\")\n    print(\"-\" * 80)\n    for m in mismatches[:10]:\n        print(f\"{m['idx']:<5} {m['gt']:<10} {m['keyword']:<10} {m['vit']:<10} {m['t5']:<10} \"\n              f\"{str(m['kw_correct']):<6} {str(m['t5_follows_kw']):<8} {str(m['t5_follows_vit']):<8}\")\n\n# 7. Key Question: Does T5 use keywords?\nprint(\"\\n\" + \"=\"*60)\nprint(\"KEY QUESTION: Does T5 Use Keyword Location?\")\nprint(\"=\"*60)\n\nt5_follows_kw = sum(1 for m in mismatches if m['t5_follows_kw'])\nt5_follows_vit = sum(1 for m in mismatches if m['t5_follows_vit'])\nt5_follows_neither = len(mismatches) - t5_follows_kw - t5_follows_vit\n\nprint(f\"\\nIn {len(mismatches)} mismatched cases:\")\nprint(f\"  T5 follows Keyword: {t5_follows_kw} ({t5_follows_kw/len(mismatches)*100:.1f}%)\")\nprint(f\"  T5 follows ViT:     {t5_follows_vit} ({t5_follows_vit/len(mismatches)*100:.1f}%)\")\nprint(f\"  T5 follows Neither: {t5_follows_neither} ({t5_follows_neither/len(mismatches)*100:.1f}%)\")\n\nif t5_follows_vit > t5_follows_kw:\n    print(\"\\n⚠️  WARNING: T5 is following ViT MORE than Keywords!\")\n    print(\"    This means T5 hasn't learned to trust keyword location.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T04:27:35.531607Z","iopub.execute_input":"2025-12-08T04:27:35.531877Z","iopub.status.idle":"2025-12-08T04:27:35.563502Z","shell.execute_reply.started":"2025-12-08T04:27:35.531850Z","shell.execute_reply":"2025-12-08T04:27:35.562575Z"}},"outputs":[{"name":"stdout","text":"=== LOCATION ACCURACY EVALUATION ===\n\n1. GROUND TRUTH LOCATIONS:\nCounter({'left': 36, 'bilateral': 24, 'right': 21, 'unknown': 15})\n\n2. KEYWORD LOCATIONS (from segmentation):\nCounter({'left': 64, 'right': 32})\n\n3. ViT PREDICTION LOCATIONS:\nCounter({'right': 71, 'left': 11, 'bilateral': 7, 'unknown': 7})\n\n4. T5 OUTPUT LOCATIONS (after adding keyword):\nCounter({'left': 52, 'right': 26, 'bilateral': 14, 'unknown': 4})\n\n============================================================\nACCURACY METRICS:\n============================================================\n\nKeyword Location Accuracy: 56/81 = 69.1%\nViT Location Accuracy:     27/78 = 34.6%\nT5 Location Accuracy:      49/79 = 62.0%\n\n============================================================\nMISMATCH ANALYSIS:\n============================================================\n\nTotal mismatches: 32/96\n\nFirst 10 mismatches:\nIdx   GT         Keyword    ViT        T5         KW✓    T5→KW    T5→ViT  \n--------------------------------------------------------------------------------\n4     right      right      right      bilateral  True   False    False   \n8     right      right      right      unknown    True   False    False   \n14    left       left       left       bilateral  True   False    False   \n15    left       left       right      bilateral  True   False    False   \n21    bilateral  left       right      left       False  True     False   \n22    bilateral  left       left       left       False  True     True    \n23    bilateral  left       right      left       False  True     False   \n24    bilateral  right      right      right      False  True     True    \n25    bilateral  right      right      right      False  True     True    \n26    bilateral  right      right      right      False  True     True    \n\n============================================================\nKEY QUESTION: Does T5 Use Keyword Location?\n============================================================\n\nIn 32 mismatched cases:\n  T5 follows Keyword: 22 (68.8%)\n  T5 follows ViT:     8 (25.0%)\n  T5 follows Neither: 2 (6.2%)\n","output_type":"stream"}],"execution_count":265}]}